From 31f5d2043ef433e9f6f730c9677ea93eea84a70f Mon Sep 17 00:00:00 2001
From: Henry Chen <henry.chen@oss.cipunited.com>
Date: Tue, 4 Jun 2024 18:00:58 +0800
Subject: [PATCH] sp_int: add MIPS64R6 support

---
 configure.ac           |   2 +-
 wolfcrypt/src/sp_int.c | 190 +++++++++++++++++++++++++++++++++++++++++
 2 files changed, 191 insertions(+), 1 deletion(-)

diff --git a/configure.ac b/configure.ac
index dec2b1e..87024a3 100644
--- a/configure.ac
+++ b/configure.ac
@@ -7960,7 +7960,7 @@ if test "$ENABLED_SP_MATH_ALL" = "yes" && test "$ENABLED_ASM" != "no"; then
   *ppc* | *powerpc*)
     AM_CFLAGS="$AM_CFLAGS -DWOLFSSL_SP_PPC"
     ;;
-  *mips64*)
+  *mips*64*)
     AM_CFLAGS="$AM_CFLAGS -DWOLFSSL_SP_MIPS64"
     ;;
   *mips*)
diff --git a/wolfcrypt/src/sp_int.c b/wolfcrypt/src/sp_int.c
index 3a6884a..d59f6e4 100644
--- a/wolfcrypt/src/sp_int.c
+++ b/wolfcrypt/src/sp_int.c
@@ -3778,6 +3778,8 @@ static WC_INLINE sp_int_digit sp_div_word(sp_int_digit hi, sp_int_digit lo,
     #endif /* WOLFSSL_SP_PPC && SP_WORD_SIZE == 64 */
 
     #if defined(WOLFSSL_SP_MIPS64) && SP_WORD_SIZE == 64
+
+        #if !defined(__mips_isa_rev) || (__mips_isa_rev < 6)
 /*
  * CPU: MIPS 64-bit
  */
@@ -3973,6 +3975,194 @@ static WC_INLINE sp_int_digit sp_div_word(sp_int_digit hi, sp_int_digit lo,
         : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
         : "$12"                                          \
     )
+        #else
+/*
+ * CPU: MIPSR6 64-bit
+ */
+
+/* Multiply va by vb and store double size result in: vh | vl */
+#define SP_ASM_MUL(vl, vh, va, vb)                       \
+    __asm__ __volatile__ (                               \
+        "dmulu	%[l], %[a], %[b]	\n\t"            \
+        "dmuhu	%[h], %[a], %[b]	\n\t"            \
+        : [h] "+r" (vh), [l] "+r" (vl)                   \
+        : [a] "r" (va), [b] "r" (vb)                     \
+        : "memory"                                       \
+    )
+/* Multiply va by vb and store double size result in: vo | vh | vl */
+#define SP_ASM_MUL_SET(vl, vh, vo, va, vb)               \
+    __asm__ __volatile__ (                               \
+        "dmulu	%[l], %[a], %[b]	\n\t"            \
+        "dmuhu	%[h], %[a], %[b]	\n\t"            \
+        "move	%[o], $0		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh), [o] "=r" (vo)    \
+        : [a] "r" (va), [b] "r" (vb)                     \
+    )
+/* Multiply va by vb and add double size result into: vo | vh | vl */
+#define SP_ASM_MUL_ADD(vl, vh, vo, va, vb)               \
+    __asm__ __volatile__ (                               \
+        "dmulu	$10, %[a], %[b]		\n\t"            \
+        "dmuhu	$11, %[a], %[b]		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "sltu	$12, %[h], $11		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
+        : [a] "r" (va), [b] "r" (vb)                     \
+        : "$10", "$11", "$12"                            \
+    )
+/* Multiply va by vb and add double size result into: vh | vl */
+#define SP_ASM_MUL_ADD_NO(vl, vh, va, vb)                \
+    __asm__ __volatile__ (                               \
+        "dmulu	$10, %[a], %[b]		\n\t"            \
+        "dmuhu	$11, %[a], %[b]		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh)                   \
+        : [a] "r" (va), [b] "r" (vb)                     \
+        : "$10", "$11", "$12"                            \
+    )
+/* Multiply va by vb and add double size result twice into: vo | vh | vl */
+#define SP_ASM_MUL_ADD2(vl, vh, vo, va, vb)              \
+    __asm__ __volatile__ (                               \
+        "dmulu	$10, %[a], %[b]		\n\t"            \
+        "dmuhu	$11, %[a], %[b]		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "sltu	$12, %[h], $11		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "sltu	$12, %[h], $11		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
+        : [a] "r" (va), [b] "r" (vb)                     \
+        : "$10", "$11", "$12"                            \
+    )
+/* Multiply va by vb and add double size result twice into: vo | vh | vl
+ * Assumes first add will not overflow vh | vl
+ */
+#define SP_ASM_MUL_ADD2_NO(vl, vh, vo, va, vb)           \
+    __asm__ __volatile__ (                               \
+        "dmulu	$10, %[a], %[b]		\n\t"            \
+        "dmuhu	$11, %[a], %[b]		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "sltu	$12, %[h], $11		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
+        : [a] "r" (va), [b] "r" (vb)                     \
+        : "$10", "$11", "$12"                            \
+    )
+/* Square va and store double size result in: vh | vl */
+#define SP_ASM_SQR(vl, vh, va)                           \
+    __asm__ __volatile__ (                               \
+        "dmulu	%[l], %[a], %[a]	\n\t"            \
+        "dmuhu	%[h], %[a], %[a]	\n\t"            \
+        : [h] "+r" (vh), [l] "+r" (vl)                   \
+        : [a] "r" (va)                                   \
+        : "memory"                                       \
+    )
+/* Square va and add double size result into: vo | vh | vl */
+#define SP_ASM_SQR_ADD(vl, vh, vo, va)                   \
+    __asm__ __volatile__ (                               \
+        "dmulu	$10, %[a], %[a]		\n\t"            \
+        "dmuhu	$11, %[a], %[a]		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "sltu	$12, %[h], $11		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
+        : [a] "r" (va)                                   \
+        : "$10", "$11", "$12"                            \
+    )
+/* Square va and add double size result into: vh | vl */
+#define SP_ASM_SQR_ADD_NO(vl, vh, va)                    \
+    __asm__ __volatile__ (                               \
+        "dmulu	$10, %[a], %[a]		\n\t"            \
+        "dmuhu	$11, %[a], %[a]		\n\t"            \
+        "daddu	%[l], %[l], $10		\n\t"            \
+        "sltu	$12, %[l], $10		\n\t"            \
+        "daddu	%[h], %[h], $11		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh)                   \
+        : [a] "r" (va)                                   \
+        : "$10", "$11", "$12"                            \
+    )
+/* Add va into: vh | vl */
+#define SP_ASM_ADDC(vl, vh, va)                          \
+    __asm__ __volatile__ (                               \
+        "daddu	%[l], %[l], %[a]	\n\t"            \
+        "sltu	$12, %[l], %[a]		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh)                   \
+        : [a] "r" (va)                                   \
+        : "$12"                                          \
+    )
+/* Sub va from: vh | vl */
+#define SP_ASM_SUBB(vl, vh, va)                          \
+    __asm__ __volatile__ (                               \
+        "move	$12, %[l]		\n\t"            \
+        "dsubu	%[l], $12, %[a]		\n\t"            \
+        "sltu	$12, $12, %[l]		\n\t"            \
+        "dsubu	%[h], %[h], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh)                   \
+        : [a] "r" (va)                                   \
+        : "$12"                                          \
+    )
+/* Add two times vc | vb | va into vo | vh | vl */
+#define SP_ASM_ADD_DBL_3(vl, vh, vo, va, vb, vc)         \
+    __asm__ __volatile__ (                               \
+        "daddu	%[l], %[l], %[a]	\n\t"            \
+        "sltu	$12, %[l], %[a]		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], %[b]	\n\t"            \
+        "sltu	$12, %[h], %[b]		\n\t"            \
+        "daddu	%[o], %[o], %[c]	\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[l], %[l], %[a]	\n\t"            \
+        "sltu	$12, %[l], %[a]		\n\t"            \
+        "daddu	%[h], %[h], $12		\n\t"            \
+        "sltu	$12, %[h], $12		\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        "daddu	%[h], %[h], %[b]	\n\t"            \
+        "sltu	$12, %[h], %[b]		\n\t"            \
+        "daddu	%[o], %[o], %[c]	\n\t"            \
+        "daddu	%[o], %[o], $12		\n\t"            \
+        : [l] "+r" (vl), [h] "+r" (vh), [o] "+r" (vo)    \
+        : [a] "r" (va), [b] "r" (vb), [c] "r" (vc)       \
+        : "$12"                                          \
+    )
+
+    #endif /* !defined(__mips_isa_rev) || (__mips_isa_rev < 6) */
 
 #define SP_INT_ASM_AVAILABLE
 
-- 
2.45.1

