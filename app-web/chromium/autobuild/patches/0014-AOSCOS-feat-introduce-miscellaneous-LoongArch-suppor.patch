From 9ac126c77e0b2407d3e4989e06ac51c20c85c29b Mon Sep 17 00:00:00 2001
From: Mingcong Bai <jeffbai@aosc.io>
Date: Tue, 24 Dec 2024 07:42:34 -0800
Subject: [PATCH 14/14] AOSCOS: feat: introduce miscellaneous LoongArch support

Link: https://github.com/AOSC-Dev/chromium-loongarch64/blob/439f324cc6443628e6c8184263f11e38f1ded5ea/chromium/chromium-131.0.6778.85.4007-loongarch64.diff
Co-authored-by: Jiajie Chen <c@jia.je>
Signed-off-by: Mingcong Bai <jeffbai@aosc.io>
---
 base/BUILD.gn                                 |  2 +-
 .../partition_allocator/partition_alloc.gni   |  2 +-
 .../src/partition_alloc/BUILD.gn              |  3 +
 .../stack/asm/loong64/push_registers_asm.cc   | 49 +++++++++++
 base/process/launch.h                         |  2 +-
 base/system/sys_info.cc                       |  2 +
 build/config/c++/BUILD.gn                     |  1 +
 build/config/rust.gni                         |  5 ++
 components/variations/proto/study.proto       |  2 +
 .../variations_field_trial_creator_base.cc    |  3 +
 content/common/user_agent.cc                  |  2 +
 third_party/angle/BUILD.gn                    |  1 +
 .../loongarch64/webgl_image_conversion_lsx.h  | 88 +++++++++----------
 .../boringssl/src/include/openssl/target.h    |  2 +
 third_party/perfetto/src/base/BUILD.gn        |  1 +
 third_party/protobuf-javascript/BUILD.gn      |  1 +
 third_party/protobuf/BUILD.gn                 |  1 +
 third_party/skia/src/opts/SkOpts_SetTarget.h  |  3 +-
 ui/qt/BUILD.gn                                |  1 +
 19 files changed, 123 insertions(+), 48 deletions(-)
 create mode 100644 base/allocator/partition_allocator/src/partition_alloc/stack/asm/loong64/push_registers_asm.cc

diff --git a/base/BUILD.gn b/base/BUILD.gn
index 4c0e4645f64..0faf08ac0ef 100644
--- a/base/BUILD.gn
+++ b/base/BUILD.gn
@@ -1015,7 +1015,7 @@ component("base") {
   defines = [ "BASE_IMPLEMENTATION" ]
   data = []
   data_deps = []
-  libs = []
+  libs = [ "m" ]
   frameworks = []
 
   configs += [
diff --git a/base/allocator/partition_allocator/partition_alloc.gni b/base/allocator/partition_allocator/partition_alloc.gni
index 17da3298e76..b58397dce42 100644
--- a/base/allocator/partition_allocator/partition_alloc.gni
+++ b/base/allocator/partition_allocator/partition_alloc.gni
@@ -304,7 +304,7 @@ declare_args() {
 
 stack_scan_supported =
     current_cpu == "x64" || current_cpu == "x86" || current_cpu == "arm" ||
-    current_cpu == "arm64" || current_cpu == "riscv64"
+    current_cpu == "arm64" || current_cpu == "riscv64" || current_cpu == "loong64"
 
 # We want to provide assertions that guard against inconsistent build
 # args, but there is no point in having them fire if we're not building
diff --git a/base/allocator/partition_allocator/src/partition_alloc/BUILD.gn b/base/allocator/partition_allocator/src/partition_alloc/BUILD.gn
index ec0b490a859..eff7e810fdb 100644
--- a/base/allocator/partition_allocator/src/partition_alloc/BUILD.gn
+++ b/base/allocator/partition_allocator/src/partition_alloc/BUILD.gn
@@ -500,6 +500,9 @@ if (is_clang_or_gcc) {
     } else if (current_cpu == "riscv64") {
       assert(stack_scan_supported)
       sources += [ "stack/asm/riscv64/push_registers_asm.cc" ]
+    } else if (current_cpu == "loong64") {
+      assert(stack_scan_supported)
+      sources += [ "stack/asm/loong64/push_registers_asm.cc" ]
     } else {
       # To support a trampoline for another arch, please refer to v8/src/heap/base.
       assert(!stack_scan_supported)
diff --git a/base/allocator/partition_allocator/src/partition_alloc/stack/asm/loong64/push_registers_asm.cc b/base/allocator/partition_allocator/src/partition_alloc/stack/asm/loong64/push_registers_asm.cc
new file mode 100644
index 00000000000..574c9ea846e
--- /dev/null
+++ b/base/allocator/partition_allocator/src/partition_alloc/stack/asm/loong64/push_registers_asm.cc
@@ -0,0 +1,49 @@
+// Copyright 2023 The Chromium Authors
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+// Push all callee-saved registers to get them on the stack for conservative
+// stack scanning.
+//
+// See asm/x64/push_registers_asm.cc for why the function is not generated
+// using clang.
+//
+// Calling convention source:
+// https://loongson.github.io/LoongArch-Documentation/LoongArch-ELF-ABI-EN.html
+asm(".global PAPushAllRegistersAndIterateStack             \n"
+    ".type PAPushAllRegistersAndIterateStack, %function    \n"
+    ".hidden PAPushAllRegistersAndIterateStack             \n"
+    "PAPushAllRegistersAndIterateStack:                    \n"
+    // Push all callee-saved registers and save return address.
+    "  addi.d $sp, $sp, -96                              \n"
+    // Save return address.
+    "  st.d $ra, $sp, 88                                 \n"
+    // sp is callee-saved.
+    "  st.d $sp, $sp, 80                                 \n"
+    // s0-s9(fp) are callee-saved.
+    "  st.d $fp, $sp, 72                                 \n"
+    "  st.d $s8, $sp, 64                                 \n"
+    "  st.d $s7, $sp, 56                                 \n"
+    "  st.d $s6, $sp, 48                                 \n"
+    "  st.d $s5, $sp, 40                                 \n"
+    "  st.d $s4, $sp, 32                                 \n"
+    "  st.d $s3, $sp, 24                                 \n"
+    "  st.d $s2, $sp, 16                                 \n"
+    "  st.d $s1, $sp, 8                                  \n"
+    "  st.d $s0, $sp, 0                                  \n"
+    // Maintain frame pointer(fp is s9).
+    "  move $fp, $sp                                     \n"
+    // Pass 1st parameter (a0) unchanged (Stack*).
+    // Pass 2nd parameter (a1) unchanged (StackVisitor*).
+    // Save 3rd parameter (a2; IterateStackCallback) to a3.
+    "  move $a3, $a2                                     \n"
+    // Pass 3rd parameter as sp (stack pointer).
+    "  move $a2, $sp                                     \n"
+    // Call the callback.
+    "  jirl $ra, $a3, 0                                  \n"
+    // Load return address.
+    "  ld.d $ra, $sp, 88                                 \n"
+    // Restore frame pointer.
+    "  ld.d $fp, $sp, 72                                 \n"
+    "  addi.d $sp, $sp, 96                               \n"
+    "  jr $ra                                            \n");
diff --git a/base/process/launch.h b/base/process/launch.h
index 009d75093c7..d570b93740c 100644
--- a/base/process/launch.h
+++ b/base/process/launch.h
@@ -55,7 +55,7 @@ namespace base {
 // defined as a constant.
 
 // These constants are borrowed from glibcâ€™s (arch)/bits/pthread_stack_min.h.
-#if defined(ARCH_CPU_ARM64)
+#if defined(ARCH_CPU_ARM64) || defined(ARCH_CPU_LOONGARCH64)
 #define PTHREAD_STACK_MIN_CONST \
   (__builtin_constant_p(PTHREAD_STACK_MIN) ? PTHREAD_STACK_MIN : 131072)
 #else
diff --git a/base/system/sys_info.cc b/base/system/sys_info.cc
index 745d42ed400..981c00f5990 100644
--- a/base/system/sys_info.cc
+++ b/base/system/sys_info.cc
@@ -261,6 +261,8 @@ std::string SysInfo::ProcessCPUArchitecture() {
   return "ARM_64";
 #elif defined(ARCH_CPU_RISCV64)
   return "RISCV_64";
+#elif defined(ARCH_CPU_LOONGARCH64)
+  return "LOONGARCH_64";
 #else
   return std::string();
 #endif
diff --git a/build/config/c++/BUILD.gn b/build/config/c++/BUILD.gn
index a6ddbe4967e..19f2eace114 100644
--- a/build/config/c++/BUILD.gn
+++ b/build/config/c++/BUILD.gn
@@ -89,6 +89,7 @@ config("runtime_library") {
     # Make sure we don't link against the system libstdc++ or libc++.
     if (is_clang) {
       ldflags += [ "-nostdlib++" ]
+      libs += [ "m" ]
     } else {
       # Gcc has a built-in abs() definition with default visibility.
       # If it was not disabled, it would conflict with libc++'s abs()
diff --git a/build/config/rust.gni b/build/config/rust.gni
index 5b7807a1b84..e3db604b944 100644
--- a/build/config/rust.gni
+++ b/build/config/rust.gni
@@ -223,6 +223,9 @@ if (is_linux || is_chromeos) {
   } else if (current_cpu == "riscv64") {
     rust_abi_target = "riscv64gc-unknown-linux-gnu"
     cargo_target_abi = ""
+  } else if (current_cpu == "loong64") {
+    rust_abi_target = "loongarch64-unknown-linux-gnu"
+    cargo_target_abi = ""
   } else {
     # Best guess for other future platforms.
     rust_abi_target = current_cpu + "-unknown-linux-gnu"
@@ -343,6 +346,8 @@ if (current_cpu == "x86") {
   rust_target_arch = "powerpc64"
 } else if (current_cpu == "riscv64") {
   rust_target_arch = "riscv64"
+} else if (current_cpu == "loong64") {
+  rust_target_arch = "loongarch64"
 }
 
 assert(!toolchain_has_rust || rust_target_arch != "")
diff --git a/components/variations/proto/study.proto b/components/variations/proto/study.proto
index 7ef5eb238e1..f2d1708e6c1 100644
--- a/components/variations/proto/study.proto
+++ b/components/variations/proto/study.proto
@@ -262,6 +262,8 @@ message Study {
     // A Mac-only value, indicating an x86-64 binary running on an arm64 host
     // via "Rosetta 2" binary translation.
     TRANSLATED_X86_64 = 4;
+
+    LOONGARCH64 = 5;
   }
 
   // Enum to pass as optional bool.
diff --git a/components/variations/service/variations_field_trial_creator_base.cc b/components/variations/service/variations_field_trial_creator_base.cc
index fbe60d2c441..f466506d41e 100644
--- a/components/variations/service/variations_field_trial_creator_base.cc
+++ b/components/variations/service/variations_field_trial_creator_base.cc
@@ -107,6 +107,9 @@ Study::CpuArchitecture GetCurrentCpuArchitecture() {
   if (process_arch == "ARM") {
     return Study::ARM32;
   }
+  if (process_arch == "LOONGARCH_64") {
+    return Study::LOONGARCH64;
+  }
   if (process_arch == "x86") {
     return Study::X86_32;
   }
diff --git a/content/common/user_agent.cc b/content/common/user_agent.cc
index 070658460eb..39bff2d78b1 100644
--- a/content/common/user_agent.cc
+++ b/content/common/user_agent.cc
@@ -174,6 +174,8 @@ std::string GetCpuArchitecture() {
               cpu_info.substr(2, 2) == "86") ||
              base::StartsWith(cpu_info, "x86")) {
     return "x86";
+  } else if (base::StartsWith(cpu_info, "loong")) {
+    return "loongarch";
   }
 #elif BUILDFLAG(IS_FUCHSIA)
   std::string cpu_arch = base::SysInfo::ProcessCPUArchitecture();
diff --git a/third_party/angle/BUILD.gn b/third_party/angle/BUILD.gn
index 511e73aa386..fc41e0a13ba 100644
--- a/third_party/angle/BUILD.gn
+++ b/third_party/angle/BUILD.gn
@@ -1443,6 +1443,7 @@ template("angle_libGLESv2") {
       sources += [ "src/libGLESv2/libGLESv2.rc" ]
       deps += [ ":angle_version" ]
     }
+    libs = [ "m" ]
   }
 }
 
diff --git a/third_party/blink/renderer/platform/graphics/cpu/loongarch64/webgl_image_conversion_lsx.h b/third_party/blink/renderer/platform/graphics/cpu/loongarch64/webgl_image_conversion_lsx.h
index 114f3c112e8..1e2096f6510 100644
--- a/third_party/blink/renderer/platform/graphics/cpu/loongarch64/webgl_image_conversion_lsx.h
+++ b/third_party/blink/renderer/platform/graphics/cpu/loongarch64/webgl_image_conversion_lsx.h
@@ -91,19 +91,19 @@ ALWAYS_INLINE void PackOneRowOfRGBA8LittleToRA8(const uint8_t*& source,
   v4f32 mask_falpha = __lsx_vffint_s_w(mask_lalpha);
   v16u8 ra_index = {0,19, 4,23, 8,27, 12,31};
   for (unsigned i = 0; i < pixels_per_row_trunc; i += 4) {
-    v16u8 bgra = *((__m128i*)(source));
+    __m128i bgra = *((__m128i*)(source));
     //if A !=0, A=0; else A=0xFF
-    v4f32 alpha_factor = __lsx_vseq_b(bgra, mask_zero);
+    __m128i alpha_factor = __lsx_vseq_b(bgra, mask_zero);
     //if A!=0, A=A; else A=0xFF
     alpha_factor = __lsx_vor_v(bgra, alpha_factor);
     alpha_factor = __lsx_vsrli_w(alpha_factor, 24);
-    alpha_factor = __lsx_vffint_s_w(alpha_factor);
-    alpha_factor = __lsx_vfdiv_s(mask_falpha, alpha_factor);
+    alpha_factor = (__m128i) __lsx_vffint_s_w(alpha_factor);
+    alpha_factor = (__m128i) __lsx_vfdiv_s((__m128) mask_falpha, (__m128) alpha_factor);
 
-    v16u8 component_r = __lsx_vand_v(bgra, mask_lalpha);
-    component_r = __lsx_vffint_s_w(component_r);
-    component_r = __lsx_vfmul_s(component_r, alpha_factor);
-    component_r = __lsx_vftintrz_w_s(component_r);
+    __m128i component_r = __lsx_vand_v(bgra, mask_lalpha);
+    component_r = (__m128i) __lsx_vffint_s_w(component_r);
+    component_r = (__m128i) __lsx_vfmul_s((__m128) component_r, (__m128) alpha_factor);
+    component_r = __lsx_vftintrz_w_s((__m128) component_r);
 
     v2u64 ra = __lsx_vshuf_b(bgra, component_r, ra_index);
     __lsx_vstelm_d(ra, destination, 0, 0);
@@ -138,19 +138,19 @@ ALWAYS_INLINE void PackOneRowOfRGBA8LittleToR8(const uint8_t*& source,
   v4u32 mask_lalpha = __lsx_vreplgr2vr_w(0x0ff);
   v4f32 mask_falpha = __lsx_vffint_s_w(mask_lalpha);
   for (unsigned i = 0; i < pixels_per_row_trunc; i += 4) {
-    v16u8 bgra = *((__m128i*)(source));
+    __m128i bgra = *((__m128i*)(source));
     //if A !=0, A=0; else A=0xFF
-    v4f32 alpha_factor = __lsx_vseq_b(bgra, mask_zero);
+    __m128i alpha_factor = __lsx_vseq_b(bgra, mask_zero);
     //if A!=0, A=A; else A=0xFF
     alpha_factor = __lsx_vor_v(bgra, alpha_factor);
     alpha_factor = __lsx_vsrli_w(alpha_factor, 24);
-    alpha_factor = __lsx_vffint_s_w(alpha_factor);
-    alpha_factor = __lsx_vfdiv_s(mask_falpha, alpha_factor);
+    alpha_factor = (__m128i) __lsx_vffint_s_w(alpha_factor);
+    alpha_factor = (__m128i) __lsx_vfdiv_s((__m128) mask_falpha, (__m128) alpha_factor);
 
-    v16u8 component_r = __lsx_vand_v(bgra, mask_lalpha);
-    component_r = __lsx_vffint_s_w(component_r);
-    component_r = __lsx_vfmul_s(component_r, alpha_factor);
-    component_r = __lsx_vftintrz_w_s(component_r);
+    __m128i component_r = __lsx_vand_v(bgra, mask_lalpha);
+    component_r = (__m128i) __lsx_vffint_s_w(component_r);
+    component_r = (__m128i) __lsx_vfmul_s((__m128) component_r, (__m128) alpha_factor);
+    component_r = __lsx_vftintrz_w_s((__m128) component_r);
 
     component_r = __lsx_vpickev_b(component_r, component_r);
     component_r = __lsx_vpickev_b(component_r, component_r);
@@ -172,41 +172,41 @@ ALWAYS_INLINE void PackOneRowOfRGBA8LittleToRGBA8(const uint8_t*& source,
   v4f32 mask_falpha = __lsx_vffint_s_w(mask_lalpha);
   v16u8 rgba_index = {0,1,2,19, 4,5,6,23, 8,9,10,27, 12,13,14,31};
   for (unsigned i = 0; i < pixels_per_row_trunc; i += 4) {
-    v16u8 bgra = *((__m128i*)(source));
+    __m128i bgra = *((__m128i*)(source));
     //if A !=0, A=0; else A=0xFF
-    v4f32 alpha_factor = __lsx_vseq_b(bgra, mask_zero);
+    __m128i alpha_factor = __lsx_vseq_b(bgra, mask_zero);
     //if A!=0, A=A; else A=0xFF
     alpha_factor = __lsx_vor_v(bgra, alpha_factor);
     alpha_factor = __lsx_vsrli_w(alpha_factor, 24);
-    alpha_factor = __lsx_vffint_s_w(alpha_factor);
-    alpha_factor = __lsx_vfdiv_s(mask_falpha, alpha_factor);
+    alpha_factor = (__m128i) __lsx_vffint_s_w(alpha_factor);
+    alpha_factor = (__m128i) __lsx_vfdiv_s((__m128) mask_falpha, (__m128) alpha_factor);
 
     v16u8 bgra_01 = __lsx_vilvl_b(mask_zero, bgra);
     v16u8 bgra_23 = __lsx_vilvh_b(mask_zero, bgra);
-    v16u8 bgra_0 = __lsx_vilvl_b(mask_zero, bgra_01);
-    v16u8 bgra_1 = __lsx_vilvh_b(mask_zero, bgra_01);
-    v16u8 bgra_2 = __lsx_vilvl_b(mask_zero, bgra_23);
-    v16u8 bgra_3 = __lsx_vilvh_b(mask_zero, bgra_23);
-
-    bgra_0 = __lsx_vffint_s_w(bgra_0);
-    bgra_1 = __lsx_vffint_s_w(bgra_1);
-    bgra_2 = __lsx_vffint_s_w(bgra_2);
-    bgra_3 = __lsx_vffint_s_w(bgra_3);
-
-    v4f32 alpha_factor_0 = __lsx_vreplvei_w(alpha_factor, 0);
-    v4f32 alpha_factor_1 = __lsx_vreplvei_w(alpha_factor, 1);
-    v4f32 alpha_factor_2 = __lsx_vreplvei_w(alpha_factor, 2);
-    v4f32 alpha_factor_3 = __lsx_vreplvei_w(alpha_factor, 3);
-
-    bgra_0 = __lsx_vfmul_s(alpha_factor_0, bgra_0);
-    bgra_1 = __lsx_vfmul_s(alpha_factor_1, bgra_1);
-    bgra_2 = __lsx_vfmul_s(alpha_factor_2, bgra_2);
-    bgra_3 = __lsx_vfmul_s(alpha_factor_3, bgra_3);
-
-    bgra_0 = __lsx_vftintrz_w_s(bgra_0);
-    bgra_1 = __lsx_vftintrz_w_s(bgra_1);
-    bgra_2 = __lsx_vftintrz_w_s(bgra_2);
-    bgra_3 = __lsx_vftintrz_w_s(bgra_3);
+    __m128i bgra_0 = __lsx_vilvl_b(mask_zero, bgra_01);
+    __m128i bgra_1 = __lsx_vilvh_b(mask_zero, bgra_01);
+    __m128i bgra_2 = __lsx_vilvl_b(mask_zero, bgra_23);
+    __m128i bgra_3 = __lsx_vilvh_b(mask_zero, bgra_23);
+
+    bgra_0 = (__m128i) __lsx_vffint_s_w(bgra_0);
+    bgra_1 = (__m128i) __lsx_vffint_s_w(bgra_1);
+    bgra_2 = (__m128i) __lsx_vffint_s_w(bgra_2);
+    bgra_3 = (__m128i) __lsx_vffint_s_w(bgra_3);
+
+    __m128i alpha_factor_0 = __lsx_vreplvei_w(alpha_factor, 0);
+    __m128i alpha_factor_1 = __lsx_vreplvei_w(alpha_factor, 1);
+    __m128i alpha_factor_2 = __lsx_vreplvei_w(alpha_factor, 2);
+    __m128i alpha_factor_3 = __lsx_vreplvei_w(alpha_factor, 3);
+
+    bgra_0 = (__m128i) __lsx_vfmul_s((__m128) alpha_factor_0, (__m128) bgra_0);
+    bgra_1 = (__m128i) __lsx_vfmul_s((__m128) alpha_factor_1, (__m128) bgra_1);
+    bgra_2 = (__m128i) __lsx_vfmul_s((__m128) alpha_factor_2, (__m128) bgra_2);
+    bgra_3 = (__m128i) __lsx_vfmul_s((__m128) alpha_factor_3, (__m128) bgra_3);
+
+    bgra_0 = __lsx_vftintrz_w_s((__m128) bgra_0);
+    bgra_1 = __lsx_vftintrz_w_s((__m128) bgra_1);
+    bgra_2 = __lsx_vftintrz_w_s((__m128) bgra_2);
+    bgra_3 = __lsx_vftintrz_w_s((__m128) bgra_3);
 
     bgra_01 = __lsx_vpickev_b(bgra_1, bgra_0);
     bgra_23 = __lsx_vpickev_b(bgra_3, bgra_2);
diff --git a/third_party/boringssl/src/include/openssl/target.h b/third_party/boringssl/src/include/openssl/target.h
index 2760f52ce8e..c53990fe8eb 100644
--- a/third_party/boringssl/src/include/openssl/target.h
+++ b/third_party/boringssl/src/include/openssl/target.h
@@ -54,6 +54,8 @@
 #define OPENSSL_32_BIT
 #elif defined(__myriad2__)
 #define OPENSSL_32_BIT
+#elif defined(__loongarch__) && __SIZEOF_POINTER__ == 8
+#define OPENSSL_64_BIT
 #else
 // The list above enumerates the platforms that BoringSSL supports. For these
 // platforms we keep a reasonable bar of not breaking them: automated test
diff --git a/third_party/perfetto/src/base/BUILD.gn b/third_party/perfetto/src/base/BUILD.gn
index ace0ac6f9bb..ab395062de4 100644
--- a/third_party/perfetto/src/base/BUILD.gn
+++ b/third_party/perfetto/src/base/BUILD.gn
@@ -80,6 +80,7 @@ perfetto_component("base") {
   if (enable_perfetto_stderr_crash_dump) {
     deps += [ ":debug_crash_stack_trace" ]
   }
+  libs = [ "m" ]
 }
 
 perfetto_component("clock_snapshots") {
diff --git a/third_party/protobuf-javascript/BUILD.gn b/third_party/protobuf-javascript/BUILD.gn
index 552cb411151..5fdb7c07ea9 100644
--- a/third_party/protobuf-javascript/BUILD.gn
+++ b/third_party/protobuf-javascript/BUILD.gn
@@ -28,5 +28,6 @@ if (current_toolchain == host_toolchain) {
       "//third_party/protobuf:protobuf_warnings",
       "//third_party/protobuf:protoc_warnings",
     ]
+    libs = [ "m" ]
   }
 }
diff --git a/third_party/protobuf/BUILD.gn b/third_party/protobuf/BUILD.gn
index 2e62cbae9df..751088a930c 100644
--- a/third_party/protobuf/BUILD.gn
+++ b/third_party/protobuf/BUILD.gn
@@ -312,6 +312,7 @@ if (current_toolchain == host_toolchain) {
     if (enable_js_protobuf) {
       deps += [ "//third_party/protobuf-javascript:protoc-gen-js" ]
     }
+    libs = [ "m" ]
   }
 }
 
diff --git a/third_party/skia/src/opts/SkOpts_SetTarget.h b/third_party/skia/src/opts/SkOpts_SetTarget.h
index 525cfcb862a..5f72a27db99 100644
--- a/third_party/skia/src/opts/SkOpts_SetTarget.h
+++ b/third_party/skia/src/opts/SkOpts_SetTarget.h
@@ -135,9 +135,10 @@
         #define SK_OPTS_NS lasx
         // The intrinsic from lasxintrin.h is wrapped by the __loongarch_asx macro, so we need to define it.
         #define __loongarch_asx
+        #define __loongarch_sx
 
         #if defined(__clang__)
-          #pragma clang attribute push(__attribute__((target("lasx"))), apply_to=function)
+          #pragma clang attribute push(__attribute__((target("lsx,lasx"))), apply_to=function)
         #endif
 
     #else
diff --git a/ui/qt/BUILD.gn b/ui/qt/BUILD.gn
index 2da7845e2e4..68148339360 100644
--- a/ui/qt/BUILD.gn
+++ b/ui/qt/BUILD.gn
@@ -99,6 +99,7 @@ template("qt_shim") {
       sources += get_target_outputs(":generate_moc" + invoker.qt_version)
       deps += [ ":generate_moc" + invoker.qt_version ]
     }
+    libs = [ "m" ]
   }
 }
 qt_shim("qt5_shim") {
-- 
2.47.1

