From 85335b971d9715fbbd6336d7275a46b2ae76671e Mon Sep 17 00:00:00 2001
From: Chao Li <lichao@loongson.cn>
Date: Thu, 18 Jul 2024 21:08:33 +0800
Subject: [PATCH 33/51] system/smp: Add LoongArch SMP support

Added LoongArch multi-core support and a way of map to node numbers if
the NUMA is enabled.

Signed-off-by: Chao Li <lichao@loongson.cn>
---
 system/smp.c | 202 +++++++++++++++++++++++++++++++++++++++++++++++++--
 1 file changed, 197 insertions(+), 5 deletions(-)

diff --git a/system/smp.c b/system/smp.c
index c78272a..39bd224 100644
--- a/system/smp.c
+++ b/system/smp.c
@@ -14,6 +14,10 @@
 #include <stdbool.h>
 #include <stdint.h>
 
+#if defined(__loongarch_lp64)
+#include <larchintrin.h>
+#endif
+
 #include "acpi.h"
 #include "boot.h"
 #include "macros.h"
@@ -29,6 +33,7 @@
 #include "string.h"
 #include "unistd.h"
 #include "vmem.h"
+#include "pmem.h"
 
 #include "smp.h"
 
@@ -94,6 +99,7 @@
 
 #define MADT_PROCESSOR                 0
 #define MADT_LAPIC_ADDR                5
+#define MADT_CORE_PIC                  17
 
 // MADT processor flag values
 
@@ -208,6 +214,7 @@ typedef struct {
     uint8_t     length;
 } madt_entry_header_t;
 
+#if defined(__i386__) || defined(__x86_64__)
 typedef struct {
     uint8_t     type;
     uint8_t     length;
@@ -215,6 +222,18 @@ typedef struct {
     uint8_t     apic_id;
     uint32_t    flags;
 } madt_processor_entry_t;
+#elif defined(__loongarch_lp64)
+#pragma pack(1)
+typedef struct {
+    uint8_t     type;
+    uint8_t     length;
+    uint8_t     version;
+    uint32_t    processor_id;
+    uint32_t    core_id;
+    uint32_t    flags;
+} madt_processor_entry_t;
+#pragma pack ()
+#endif
 
 typedef struct {
     uint8_t     type;
@@ -301,9 +320,11 @@ static uintptr_t         alloc_addr = 0;
 // Variables
 //------------------------------------------------------------------------------
 
-int num_available_cpus = 1;  // There is always at least one CPU, the BSP
-int num_memory_affinity_ranges = 0;
-int num_proximity_domains = 0;
+int     num_available_cpus = 1;  // There is always at least one CPU, the BSP
+int     num_memory_affinity_ranges = 0;
+int     num_proximity_domains = 0;
+bool    map_numa_memory_range = false;
+uint8_t highest_map_bit = 0;
 
 //------------------------------------------------------------------------------
 // Private Functions
@@ -311,9 +332,14 @@ int num_proximity_domains = 0;
 
 static int my_apic_id(void)
 {
+#if defined(__i386__) || defined(__x86_64__)
     return read32(&apic[APIC_REG_ID][0]) >> 24;
+#elif defined(__loongarch_lp64)
+    return ((int)__csrrd_w(0x20));
+#endif
 }
 
+#if defined(__i386__) || defined(__x86_64__)
 static void apic_write(int reg, uint32_t val)
 {
     write32(&apic[reg][0], val);
@@ -445,6 +471,7 @@ static bool find_cpus_in_floating_mp_struct(void)
 
     return false;
 }
+#endif
 
 static bool find_cpus_in_madt(void)
 {
@@ -470,6 +497,7 @@ static bool find_cpus_in_madt(void)
     uint8_t *mpc_table_end = (uint8_t *)mpc + mpc->h.length;
     while (tab_entry_ptr < mpc_table_end) {
         madt_entry_header_t *entry_header = (madt_entry_header_t *)tab_entry_ptr;
+#if defined(__i386__) || defined(__x86_64__)
         if (entry_header->type == MADT_PROCESSOR) {
             if (entry_header->length != sizeof(madt_processor_entry_t)) {
                 return false;
@@ -493,6 +521,21 @@ static bool find_cpus_in_madt(void)
             madt_lapic_addr_entry_t *entry = (madt_lapic_addr_entry_t *)tab_entry_ptr;
             apic_addr = (uintptr_t)entry->lapic_addr;
         }
+#elif defined(__loongarch_lp64)
+        if (entry_header->type == MADT_CORE_PIC) {
+            madt_processor_entry_t *entry = (madt_processor_entry_t *)tab_entry_ptr;
+            if (entry->flags & (MADT_PF_ENABLED|MADT_PF_ONLINE_CAPABLE)) {
+                if (num_available_cpus < MAX_CPUS) {
+                    cpu_num_to_apic_id[found_cpus] = entry->core_id;
+                    // The first CPU is the BSP, don't increment.
+                    if (found_cpus > 0) {
+                        num_available_cpus++;
+                    }
+                }
+                found_cpus++;
+            }
+        }
+#endif
         tab_entry_ptr += entry_header->length;
     }
 
@@ -682,11 +725,26 @@ static bool parse_slit(uintptr_t slit_addr)
 }
 #endif
 
-static inline void send_ipi(int apic_id, int trigger, int level, int mode, uint8_t vector)
+static inline void send_ipi(int apic_id, int trigger __attribute__((unused)), int level __attribute__((unused)), int mode, uint8_t vector)
 {
+#if defined(__i386__) || defined(__x86_64__)
     apic_write(APIC_REG_ICRHI, apic_id << 24);
 
     apic_write(APIC_REG_ICRLO, trigger << 15 | level << 14 | mode << 8 | vector);
+#elif defined(__loongarch_lp64)
+    if (mode == APIC_DELMODE_STARTUP) {
+        //
+        // Set the AP mailbox0
+        //
+        __iocsrwr_d((1ULL << 31 | ((0x0 << 1) + 1) << 2 | apic_id << 16 | (((uintptr_t)ap_startup_addr) & 0xFFFFFFFF00000000ULL)), 0x1048);
+        __iocsrwr_d((1ULL << 31 | (0x0 << 1) << 2 | apic_id << 16 | (((uintptr_t)ap_startup_addr << 32))), 0x1048);
+    }
+
+    //
+    // Trigger IPI interrupt
+    //
+    __iocsrwr_d((1<<31 | apic_id << 16 | vector), 0x1040);
+#endif
 }
 
 static bool send_ipi_and_wait(int apic_id, int trigger, int level, int mode, uint8_t vector, int delay_before_poll)
@@ -697,6 +755,7 @@ static bool send_ipi_and_wait(int apic_id, int trigger, int level, int mode, uin
 
     // Wait for send complete or timeout after 100ms.
     int timeout = 1000;
+#if defined(__i386__) || defined(__x86_64__)
     while (timeout > 0) {
         bool send_pending = (apic_read(APIC_REG_ICRLO) & APIC_ICR_BUSY);
         if (!send_pending) {
@@ -706,8 +765,16 @@ static bool send_ipi_and_wait(int apic_id, int trigger, int level, int mode, uin
         timeout--;
     }
     return false;
+#elif defined(__loongarch_lp64)
+    while (timeout > 0) {
+        usleep(100);
+        timeout--;
+    }
+    return true;
+#endif
 }
 
+#if defined(__i386__) || defined(__x86_64__)
 static uint32_t read_apic_esr(bool is_p5)
 {
     if (!is_p5) {
@@ -769,6 +836,108 @@ static bool start_cpu(int cpu_num)
 
     return true;
 }
+#elif defined(__loongarch_lp64)
+static bool start_cpu(int cpu_num)
+{
+    int apic_id = cpu_num_to_apic_id[cpu_num];
+    bool use_long_delays = false;
+
+    // Send the STARTUP IPI.
+    if (!send_ipi_and_wait(apic_id, 0, 0, APIC_DELMODE_STARTUP, 0, use_long_delays ? 300 : 10)) {
+        return false;
+    }
+    // Give the other CPU some time to accept the IPI.
+    usleep(use_long_delays ? 200 : 10);
+
+    return true;
+}
+#endif
+
+#if defined(__loongarch_lp64)
+uint8_t checkout_max_memory_bits_of_this_numa_node(uint8_t range)
+{
+    uint64_t max_memory_range = memory_affinity_ranges[range].end & (~(0xFULL << 44));
+    uint8_t  bits = 0;
+
+    if (max_memory_range > 0x0) {
+        do {
+            bits++;
+            max_memory_range = max_memory_range >> 1;
+        } while (max_memory_range > 0x1);
+    } else {
+        return 0;
+    }
+
+    return bits;
+}
+
+void map_the_numa_memory_range(uint8_t highest_bit)
+{
+    uint8_t i, node_nu;
+    uint8_t node_offset = 44;
+
+    //
+    // First step, map the pm_map.
+    //
+    for (i = 0; i < pm_map_size; i++) {
+        node_nu = (pm_map[i].start >> (node_offset - PAGE_SHIFT)) & 0xF;
+        if (node_nu != 0) {
+            pm_map[i].start &= ~((uint64_t)0xF << (node_offset - PAGE_SHIFT));
+            pm_map[i].start |= node_nu << (highest_bit - PAGE_SHIFT);
+
+            pm_map[i].end &= ~((uint64_t)0xF << (node_offset - PAGE_SHIFT));
+            pm_map[i].end |= node_nu << (highest_bit - PAGE_SHIFT);
+        }
+    }
+
+    //
+    // Second step, map the memory_affinity_ranges.
+    //
+    for (i = 0; i < num_memory_affinity_ranges; i++) {
+        if (memory_affinity_ranges[i].proximity_domain_idx != 0) {
+            node_nu = (memory_affinity_ranges[i].start >> node_offset) & 0xF;
+            if (node_nu != 0) {
+                memory_affinity_ranges[i].start &= ~((uint64_t)0xF << node_offset);
+                memory_affinity_ranges[i].start |= node_nu << highest_bit;
+                memory_affinity_ranges[i].end   &= ~((uint64_t)0xF << node_offset);
+                memory_affinity_ranges[i].end   |= node_nu << highest_bit;
+            }
+        }
+    }
+}
+
+void check_if_needs_to_map(void)
+{
+    uint8_t  i, local_memory_area_bits;
+    uint8_t  max_memory_bits = 0x0;
+
+    if (num_proximity_domains == 0x0) {
+        return;
+    } else {
+        for (i = 0; i < num_memory_affinity_ranges; i++) {
+            if (memory_affinity_ranges[i].proximity_domain_idx != 0) {
+                local_memory_area_bits = checkout_max_memory_bits_of_this_numa_node(i);
+                if (max_memory_bits < local_memory_area_bits) {
+                    max_memory_bits = local_memory_area_bits;
+                }
+            }
+        }
+        if (max_memory_bits > 0) {
+            map_numa_memory_range = true;
+            highest_map_bit = max_memory_bits + 1;
+            map_the_numa_memory_range(highest_map_bit);
+        }
+    }
+}
+#else
+void check_if_needs_to_map(void)
+{
+    //
+    // It is an empty function if not LoongArch64.
+    //
+    return;
+}
+#endif
 
 //------------------------------------------------------------------------------
 // Public Functions
@@ -805,6 +974,7 @@ void smp_init(bool smp_enable)
     num_memory_affinity_ranges = 0;
     num_proximity_domains = 0;
 
+#if defined(__i386__) || defined(__x86_64__)
     if (cpuid_info.flags.x2apic) {
         uint32_t msrl, msrh;
         rdmsr(MSR_IA32_APIC_BASE, msrl, msrh);
@@ -813,6 +983,7 @@ void smp_init(bool smp_enable)
             smp_enable = false;
         }
     }
+#endif
 
     // Process SMP Quirks
     if (quirk.type & QUIRK_TYPE_SMP) {
@@ -821,7 +992,11 @@ void smp_init(bool smp_enable)
     }
 
     if (smp_enable) {
+#if defined(__i386__) || defined(__x86_64__)
         (void)(find_cpus_in_madt() || find_cpus_in_floating_mp_struct());
+#else
+        find_cpus_in_madt();
+#endif
     }
 
     for (int i = 0; i < num_available_cpus; i++) {
@@ -829,7 +1004,9 @@ void smp_init(bool smp_enable)
     }
 
     if (smp_enable) {
-        if (!find_numa_nodes_in_srat()) {
+        if (find_numa_nodes_in_srat()) {
+            check_if_needs_to_map();
+        } else {
             // Do nothing.
         }
     }
@@ -843,12 +1020,17 @@ void smp_init(bool smp_enable)
     // These need to remain pinned in place during relocation.
     smp_heap_page = heap_alloc(HEAP_TYPE_LM_1, PAGE_SIZE, PAGE_SIZE) >> PAGE_SHIFT;
 
+#if defined(__i386__) || defined(__x86_64__)
     ap_startup_addr = (uintptr_t)startup;
 
     size_t ap_trampoline_size = ap_trampoline_end - ap_trampoline;
     memcpy((uint8_t *)HEAP_BASE_ADDR, ap_trampoline, ap_trampoline_size);
 
     alloc_addr = HEAP_BASE_ADDR + ap_trampoline_size;
+#elif defined(__loongarch_lp64)
+    ap_startup_addr = (uintptr_t)startup64;
+    alloc_addr = HEAP_BASE_ADDR;
+#endif
 }
 
 int smp_start(cpu_state_t cpu_state[MAX_CPUS])
@@ -876,6 +1058,14 @@ int smp_start(cpu_state_t cpu_state[MAX_CPUS])
 #endif
     }
 
+#if defined(__loongarch_lp64)
+    //
+    // MP sync the PMCNT with AP
+    //
+    __csrxchg_d(1 << 16, (1 << 16 | 0x3FF), 0x200);
+    __csrwr_d(0x0, 0x201);
+#endif
+
 #if SEQUENTIAL_AP_START
     return 0;
 #else
@@ -896,9 +1086,11 @@ int smp_start(cpu_state_t cpu_state[MAX_CPUS])
 
 void smp_send_nmi(int cpu_num)
 {
+#if defined(__i386__) || defined(__x86_64__)
     while (apic_read(APIC_REG_ICRLO) & APIC_ICR_BUSY) {
         __builtin_ia32_pause();
     }
+#endif
     send_ipi(cpu_num_to_apic_id[cpu_num], 0, 0, APIC_DELMODE_NMI, 0);
 }
 
-- 
2.46.0

