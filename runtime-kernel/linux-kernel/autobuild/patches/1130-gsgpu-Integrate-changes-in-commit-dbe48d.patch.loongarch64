From d366214e65534a54318736e50497852d6943e10a Mon Sep 17 00:00:00 2001
From: "Dr. Chang Liu, PhD" <cl91tp@gmail.com>
Date: Thu, 5 Oct 2023 16:58:03 +0800
Subject: [PATCH] gsgpu: Integrate changes in commit dbe48d030b2

Also fixes some comments
---
 drivers/gpu/drm/gsgpu/gpu/gsgpu_cs.c  |  2 ++
 drivers/gpu/drm/gsgpu/gpu/gsgpu_ib.c  |  2 +-
 drivers/gpu/drm/gsgpu/gpu/gsgpu_job.c |  2 ++
 drivers/gpu/drm/gsgpu/gpu/gsgpu_sa.c  |  2 +-
 drivers/gpu/drm/gsgpu/gpu/gsgpu_vm.c  | 19 ++++++++++---------
 5 files changed, 16 insertions(+), 11 deletions(-)

diff --git a/drivers/gpu/drm/gsgpu/gpu/gsgpu_cs.c b/drivers/gpu/drm/gsgpu/gpu/gsgpu_cs.c
index d4fd5586b548..cba6aa23c28f 100644
--- a/drivers/gpu/drm/gsgpu/gpu/gsgpu_cs.c
+++ b/drivers/gpu/drm/gsgpu/gpu/gsgpu_cs.c
@@ -1020,6 +1020,8 @@ static int gsgpu_cs_submit(struct gsgpu_cs_parser *p,
 	if (r)
 		goto error_unlock;
 
+	drm_sched_job_arm(&job->base);
+
 	/* No memory allocation is allowed while holding the notifier lock.
 	 * The lock is held until gsgpu_cs_submit is finished and fence is
 	 * added to BOs.
diff --git a/drivers/gpu/drm/gsgpu/gpu/gsgpu_ib.c b/drivers/gpu/drm/gsgpu/gpu/gsgpu_ib.c
index df38e8f6a085..56dc56a91ed7 100644
--- a/drivers/gpu/drm/gsgpu/gpu/gsgpu_ib.c
+++ b/drivers/gpu/drm/gsgpu/gpu/gsgpu_ib.c
@@ -7,7 +7,7 @@
 
 /*
  * IB
- * IBs (Indirect Buffers) and areas of GPU accessible memory where
+ * IBs (Indirect Buffers) are areas of GPU accessible memory where
  * commands are stored.  You can put a pointer to the IB in the
  * command ring and the hw will fetch the commands from the IB
  * and execute them.  Generally userspace acceleration drivers
diff --git a/drivers/gpu/drm/gsgpu/gpu/gsgpu_job.c b/drivers/gpu/drm/gsgpu/gpu/gsgpu_job.c
index 9a8f92bcbd2a..2e4d9a1c2e51 100644
--- a/drivers/gpu/drm/gsgpu/gpu/gsgpu_job.c
+++ b/drivers/gpu/drm/gsgpu/gpu/gsgpu_job.c
@@ -115,6 +115,8 @@ int gsgpu_job_submit(struct gsgpu_job *job, struct drm_sched_entity *entity,
 	if (r)
 		return r;
 
+	drm_sched_job_arm(&job->base);
+
 	job->owner = owner;
 	*f = dma_fence_get(&job->base.s_fence->finished);
 	gsgpu_job_free_resources(job);
diff --git a/drivers/gpu/drm/gsgpu/gpu/gsgpu_sa.c b/drivers/gpu/drm/gsgpu/gpu/gsgpu_sa.c
index 334bc72196c4..e6ddfa3adb0f 100644
--- a/drivers/gpu/drm/gsgpu/gpu/gsgpu_sa.c
+++ b/drivers/gpu/drm/gsgpu/gpu/gsgpu_sa.c
@@ -31,7 +31,7 @@ int gsgpu_sa_bo_manager_init(struct gsgpu_device *adev,
 }
 
 void gsgpu_sa_bo_manager_fini(struct gsgpu_device *adev,
-					struct gsgpu_sa_manager *sa_manager)
+			      struct gsgpu_sa_manager *sa_manager)
 {
 	struct gsgpu_sa_bo *sa_bo, *tmp;
 
diff --git a/drivers/gpu/drm/gsgpu/gpu/gsgpu_vm.c b/drivers/gpu/drm/gsgpu/gpu/gsgpu_vm.c
index 8b09de0cbe2e..6512f1a161f8 100644
--- a/drivers/gpu/drm/gsgpu/gpu/gsgpu_vm.c
+++ b/drivers/gpu/drm/gsgpu/gpu/gsgpu_vm.c
@@ -13,8 +13,8 @@
  * GPUVM is similar to the legacy gart on older asics, however
  * rather than there being a single global gart table
  * for the entire GPU, there are multiple VM page tables active
- * at any given time.  The VM page tables can contain a mix
- * vram pages and system memory pages and system memory pages
+ * at any given time.  The VM page tables can contain a mix of
+ * vram pages and system memory pages, and system memory pages
  * can be mapped as snooped (cached system pages) or unsnooped
  * (uncached system pages).
  * Each VM has an ID associated with it and there is a page table
@@ -139,7 +139,7 @@ static void gsgpu_vm_bo_base_init(struct gsgpu_vm_bo_base *base,
 	base->moved = true;
 }
 
-static u32 gsgpu_get_pde_pte_size (struct gsgpu_device *ldev)
+static u32 gsgpu_get_pde_pte_size(struct gsgpu_device *ldev)
 {
 	return ldev->vm_manager.pde_pte_bytes;
 }
@@ -169,7 +169,8 @@ static unsigned gsgpu_vm_level_shift(struct gsgpu_device *ldev,
 		shift = 0;
 		break;
 	default:
-		dev_err(ldev->dev, "the level%d isn't supported.\n", level);
+		dev_err(ldev->dev, "the vm level %d isn't supported.\n", level);
+		BUG();
 	}
 
 	return shift;
@@ -200,7 +201,8 @@ static unsigned gsgpu_vm_num_entries(struct gsgpu_device *ldev,
 		width = ldev->vm_manager.dir2_width;
 		break;
 	default:
-		dev_err(ldev->dev, "the level%d isn't supported.\n", level);
+		dev_err(ldev->dev, "the vm level %d isn't supported.\n", level);
+		BUG();
 	}
 
 	return 1 << width;
@@ -2207,7 +2209,7 @@ void gsgpu_vm_adjust_size(struct gsgpu_device *ldev, u32 min_vm_size,
  *
  * @ldev: gsgpu_device pointer
  * @vm: requested vm
- * @vm_context: Indicates if it GFX or Compute context
+ * @vm_context: Indicates if it is a GFX or Compute context
  * @pasid: Process address space identifier
  *
  * Init @vm fields.
@@ -2216,7 +2218,7 @@ void gsgpu_vm_adjust_size(struct gsgpu_device *ldev, u32 min_vm_size,
  * 0 for success, error for failure.
  */
 int gsgpu_vm_init(struct gsgpu_device *ldev, struct gsgpu_vm *vm,
-		   int vm_context, unsigned int pasid)
+		  int vm_context, unsigned int pasid)
 {
 	struct gsgpu_bo_param bp;
 	struct gsgpu_bo *root;
@@ -2239,7 +2241,6 @@ int gsgpu_vm_init(struct gsgpu_device *ldev, struct gsgpu_vm *vm,
 	INIT_LIST_HEAD(&vm->freed);
 
 	/* create scheduler entity for page table updates */
-
 	ring_instance = atomic_inc_return(&ldev->vm_manager.vm_pte_next_ring);
 	ring_instance %= ldev->vm_manager.vm_pte_num_rings;
 	ring = ldev->vm_manager.vm_pte_rings[ring_instance];
@@ -2282,7 +2283,7 @@ int gsgpu_vm_init(struct gsgpu_device *ldev, struct gsgpu_vm *vm,
 		goto error_free_root;
 
 	r = gsgpu_vm_clear_bo(ldev, vm, root,
-			       ldev->vm_manager.root_level);
+			      ldev->vm_manager.root_level);
 	if (r)
 		goto error_unreserve;
 
-- 
2.43.0

