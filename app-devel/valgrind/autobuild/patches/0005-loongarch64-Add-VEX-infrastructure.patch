From fdb9ee510b8e49922b36ecd342488fa348164a14 Mon Sep 17 00:00:00 2001
From: Feiyang Chen <chenfeiyang@loongson.cn>
Date: Sat, 6 Aug 2022 15:59:47 +0800
Subject: [PATCH v4 005/123] loongarch64: Add VEX infrastructure

---
 Makefile.vex.am                      |  14 +-
 VEX/auxprogs/genoffsets.c            |  36 ++
 VEX/priv/guest_loongarch64_defs.h    |  73 ++++
 VEX/priv/guest_loongarch64_helpers.c | 237 +++++++++++++
 VEX/priv/guest_loongarch64_toIR.c    | 504 +++++++++++++++++++++++++++
 VEX/priv/host_loongarch64_defs.c     | 362 +++++++++++++++++++
 VEX/priv/host_loongarch64_defs.h     | 190 ++++++++++
 VEX/priv/host_loongarch64_isel.c     |  59 ++++
 VEX/priv/main_main.c                 | 109 ++++++
 VEX/pub/libvex.h                     |  21 ++
 VEX/pub/libvex_basictypes.h          |   4 +
 VEX/pub/libvex_guest_loongarch64.h   | 171 +++++++++
 12 files changed, 1777 insertions(+), 3 deletions(-)
 create mode 100644 VEX/priv/guest_loongarch64_defs.h
 create mode 100644 VEX/priv/guest_loongarch64_helpers.c
 create mode 100644 VEX/priv/guest_loongarch64_toIR.c
 create mode 100644 VEX/priv/host_loongarch64_defs.c
 create mode 100644 VEX/priv/host_loongarch64_defs.h
 create mode 100644 VEX/priv/host_loongarch64_isel.c
 create mode 100644 VEX/pub/libvex_guest_loongarch64.h

diff --git a/Makefile.vex.am b/Makefile.vex.am
index 98d848359..009d93b45 100644
--- a/Makefile.vex.am
+++ b/Makefile.vex.am
@@ -26,6 +26,7 @@ pkginclude_HEADERS = \
 	pub/libvex_guest_s390x.h \
 	pub/libvex_guest_mips32.h \
 	pub/libvex_guest_mips64.h \
+	pub/libvex_guest_loongarch64.h \
 	pub/libvex_s390x_common.h \
 	pub/libvex_ir.h \
 	pub/libvex_trc_values.h \
@@ -49,6 +50,7 @@ noinst_HEADERS = \
 	priv/guest_mips_defs.h \
 	priv/mips_defs.h \
 	priv/guest_nanomips_defs.h \
+	priv/guest_loongarch64_defs.h \
 	priv/host_generic_regs.h \
 	priv/host_generic_simd64.h \
 	priv/host_generic_simd128.h \
@@ -64,7 +66,8 @@ noinst_HEADERS = \
 	priv/s390_defs.h \
 	priv/host_mips_defs.h \
 	priv/host_nanomips_defs.h \
-	priv/common_nanomips_defs.h
+	priv/common_nanomips_defs.h \
+	priv/host_loongarch64_defs.h
 
 BUILT_SOURCES = pub/libvex_guest_offsets.h
 CLEANFILES    = pub/libvex_guest_offsets.h
@@ -93,7 +96,8 @@ pub/libvex_guest_offsets.h: auxprogs/genoffsets.c \
 			    pub/libvex_guest_arm64.h \
 			    pub/libvex_guest_s390x.h \
 			    pub/libvex_guest_mips32.h \
-			    pub/libvex_guest_mips64.h
+			    pub/libvex_guest_mips64.h \
+			    pub/libvex_guest_loongarch64.h
 	rm -f auxprogs/genoffsets.s
 	$(mkdir_p) auxprogs pub
 	$(CC) $(CFLAGS_FOR_GENOFFSETS) \
@@ -151,6 +155,8 @@ LIBVEX_SOURCES_COMMON = \
 	priv/guest_mips_toIR.c \
 	priv/guest_nanomips_helpers.c \
 	priv/guest_nanomips_toIR.c \
+	priv/guest_loongarch64_helpers.c \
+	priv/guest_loongarch64_toIR.c \
 	priv/host_generic_regs.c \
 	priv/host_generic_simd64.c \
 	priv/host_generic_simd128.c \
@@ -174,7 +180,9 @@ LIBVEX_SOURCES_COMMON = \
 	priv/host_mips_defs.c \
 	priv/host_nanomips_defs.c \
 	priv/host_mips_isel.c \
-	priv/host_nanomips_isel.c
+	priv/host_nanomips_isel.c \
+	priv/host_loongarch64_defs.c \
+	priv/host_loongarch64_isel.c
 
 LIBVEXMULTIARCH_SOURCES = priv/multiarch_main_main.c
 
diff --git a/VEX/auxprogs/genoffsets.c b/VEX/auxprogs/genoffsets.c
index 54376dc90..89edf524c 100644
--- a/VEX/auxprogs/genoffsets.c
+++ b/VEX/auxprogs/genoffsets.c
@@ -53,6 +53,7 @@
 #include "../pub/libvex_guest_s390x.h"
 #include "../pub/libvex_guest_mips32.h"
 #include "../pub/libvex_guest_mips64.h"
+#include "../pub/libvex_guest_loongarch64.h"
 
 #define VG_STRINGIFZ(__str)  #__str
 #define VG_STRINGIFY(__str)  VG_STRINGIFZ(__str)
@@ -262,6 +263,41 @@ void foo ( void )
    GENOFFSET(MIPS64,mips64,PC);
    GENOFFSET(MIPS64,mips64,HI);
    GENOFFSET(MIPS64,mips64,LO);
+
+   // LOONGARCH64
+   GENOFFSET(LOONGARCH64,loongarch64,R0);
+   GENOFFSET(LOONGARCH64,loongarch64,R1);
+   GENOFFSET(LOONGARCH64,loongarch64,R2);
+   GENOFFSET(LOONGARCH64,loongarch64,R3);
+   GENOFFSET(LOONGARCH64,loongarch64,R4);
+   GENOFFSET(LOONGARCH64,loongarch64,R5);
+   GENOFFSET(LOONGARCH64,loongarch64,R6);
+   GENOFFSET(LOONGARCH64,loongarch64,R7);
+   GENOFFSET(LOONGARCH64,loongarch64,R8);
+   GENOFFSET(LOONGARCH64,loongarch64,R9);
+   GENOFFSET(LOONGARCH64,loongarch64,R10);
+   GENOFFSET(LOONGARCH64,loongarch64,R11);
+   GENOFFSET(LOONGARCH64,loongarch64,R12);
+   GENOFFSET(LOONGARCH64,loongarch64,R13);
+   GENOFFSET(LOONGARCH64,loongarch64,R14);
+   GENOFFSET(LOONGARCH64,loongarch64,R15);
+   GENOFFSET(LOONGARCH64,loongarch64,R16);
+   GENOFFSET(LOONGARCH64,loongarch64,R17);
+   GENOFFSET(LOONGARCH64,loongarch64,R18);
+   GENOFFSET(LOONGARCH64,loongarch64,R19);
+   GENOFFSET(LOONGARCH64,loongarch64,R20);
+   GENOFFSET(LOONGARCH64,loongarch64,R21);
+   GENOFFSET(LOONGARCH64,loongarch64,R22);
+   GENOFFSET(LOONGARCH64,loongarch64,R23);
+   GENOFFSET(LOONGARCH64,loongarch64,R24);
+   GENOFFSET(LOONGARCH64,loongarch64,R25);
+   GENOFFSET(LOONGARCH64,loongarch64,R26);
+   GENOFFSET(LOONGARCH64,loongarch64,R27);
+   GENOFFSET(LOONGARCH64,loongarch64,R28);
+   GENOFFSET(LOONGARCH64,loongarch64,R29);
+   GENOFFSET(LOONGARCH64,loongarch64,R30);
+   GENOFFSET(LOONGARCH64,loongarch64,R31);
+   GENOFFSET(LOONGARCH64,loongarch64,PC);
 }
 
 /*--------------------------------------------------------------------*/
diff --git a/VEX/priv/guest_loongarch64_defs.h b/VEX/priv/guest_loongarch64_defs.h
new file mode 100644
index 000000000..883be38b8
--- /dev/null
+++ b/VEX/priv/guest_loongarch64_defs.h
@@ -0,0 +1,73 @@
+
+/*---------------------------------------------------------------*/
+/*--- begin                          guest_loongarch64_defs.h ---*/
+/*---------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+*/
+
+/* Only to be used within the guest-loongarch64 directory. */
+
+#ifndef __VEX_GUEST_LOONGARCH64_DEFS_H
+#define __VEX_GUEST_LOONGARCH64_DEFS_H
+
+#include "libvex_basictypes.h"
+#include "guest_generic_bb_to_IR.h"  /* DisResult */
+
+
+/*---------------------------------------------------------*/
+/*--- loongarch64 to IR conversion                      ---*/
+/*---------------------------------------------------------*/
+
+/* Convert one LOONGARCH64 insn to IR.  See the type DisOneInstrFn in
+   guest_generic_bb_to_IR.h. */
+extern DisResult disInstr_LOONGARCH64 ( IRSB*              irsb_IN,
+                                        const UChar*       guest_code_IN,
+                                        Long               delta,
+                                        Addr               guest_IP,
+                                        VexArch            guest_arch,
+                                        const VexArchInfo* archinfo,
+                                        const VexAbiInfo*  abiinfo,
+                                        VexEndness         host_endness_IN,
+                                        Bool               sigill_diag_IN );
+
+/* Used by the optimiser to specialise calls to helpers. */
+extern IRExpr* guest_loongarch64_spechelper ( const HChar* function_name,
+                                              IRExpr**     args,
+                                              IRStmt**     precedingStmts,
+                                              Int          n_precedingStmts );
+
+/* Describes to the optimser which part of the guest state require
+   precise memory exceptions.  This is logically part of the guest
+   state description. */
+extern Bool guest_loongarch64_state_requires_precise_mem_exns ( Int minoff,
+                                                                Int maxoff,
+                                                                VexRegisterUpdates pxControl );
+
+extern VexGuestLayout loongarch64Guest_layout;
+
+#endif /* ndef __VEX_GUEST_LOONGARCH64_DEFS_H */
+
+
+/*---------------------------------------------------------------*/
+/*--- end                            guest_loongarch64_defs.h ---*/
+/*---------------------------------------------------------------*/
diff --git a/VEX/priv/guest_loongarch64_helpers.c b/VEX/priv/guest_loongarch64_helpers.c
new file mode 100644
index 000000000..e3c402023
--- /dev/null
+++ b/VEX/priv/guest_loongarch64_helpers.c
@@ -0,0 +1,237 @@
+
+/*---------------------------------------------------------------*/
+/*--- begin                       guest_loongarch64_helpers.c ---*/
+/*---------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+*/
+
+#include "libvex_basictypes.h"
+#include "libvex_emnote.h"
+#include "libvex_guest_loongarch64.h"
+#include "libvex_ir.h"
+#include "libvex.h"
+
+#include "main_util.h"
+#include "main_globals.h"
+#include "guest_generic_bb_to_IR.h"
+#include "guest_loongarch64_defs.h"
+
+
+/* This file contains helper functions for loongarch64 guest code.
+   Calls to these functions are generated by the back end. */
+
+IRExpr* guest_loongarch64_spechelper ( const HChar * function_name,
+                                       IRExpr ** args,
+                                       IRStmt ** precedingStmts,
+                                       Int n_precedingStmts )
+{
+   return NULL;
+}
+
+/* VISIBLE TO LIBVEX CLIENT */
+void LibVEX_GuestLOONGARCH64_initialise ( /*OUT*/
+                                          VexGuestLOONGARCH64State* vex_state )
+{
+   /* Event check fail addr and counter. */
+   vex_state->host_EvC_FAILADDR = 0;
+   vex_state->host_EvC_COUNTER  = 0;
+
+   /* CPU Registers */
+   vex_state->guest_R0   = 0; /* Constant zero */
+   vex_state->guest_R1   = 0; /* Return address */
+   vex_state->guest_R2   = 0; /* Thread pointer */
+   vex_state->guest_R3   = 0; /* Stack pointer */
+   vex_state->guest_R4   = 0; /* Argument registers / Return value */
+   vex_state->guest_R5   = 0;
+   vex_state->guest_R6   = 0; /* Argument registers */
+   vex_state->guest_R7   = 0;
+   vex_state->guest_R8   = 0;
+   vex_state->guest_R9   = 0;
+   vex_state->guest_R10  = 0;
+   vex_state->guest_R11  = 0;
+   vex_state->guest_R12  = 0; /* Temporary registers */
+   vex_state->guest_R13  = 0;
+   vex_state->guest_R14  = 0;
+   vex_state->guest_R15  = 0;
+   vex_state->guest_R16  = 0;
+   vex_state->guest_R17  = 0;
+   vex_state->guest_R18  = 0;
+   vex_state->guest_R19  = 0;
+   vex_state->guest_R20  = 0;
+   vex_state->guest_R21  = 0; /* Reserved */
+   vex_state->guest_R22  = 0; /* Frame pointer / Static register */
+   vex_state->guest_R23  = 0; /* Static registers */
+   vex_state->guest_R24  = 0;
+   vex_state->guest_R25  = 0;
+   vex_state->guest_R26  = 0;
+   vex_state->guest_R27  = 0;
+   vex_state->guest_R28  = 0;
+   vex_state->guest_R29  = 0;
+   vex_state->guest_R30  = 0;
+   vex_state->guest_R31  = 0;
+
+   vex_state->guest_PC   = 0; /* Program counter */
+
+   /* FPU Registers */
+   vex_state->guest_F0   = 0xffffffffffffffffULL; /* Argument registers / Return value */
+   vex_state->guest_F1   = 0xffffffffffffffffULL;
+   vex_state->guest_F2   = 0xffffffffffffffffULL; /* Argument registers */
+   vex_state->guest_F3   = 0xffffffffffffffffULL;
+   vex_state->guest_F4   = 0xffffffffffffffffULL;
+   vex_state->guest_F5   = 0xffffffffffffffffULL;
+   vex_state->guest_F6   = 0xffffffffffffffffULL;
+   vex_state->guest_F7   = 0xffffffffffffffffULL;
+   vex_state->guest_F8   = 0xffffffffffffffffULL; /* Temporary registers */
+   vex_state->guest_F9   = 0xffffffffffffffffULL;
+   vex_state->guest_F10  = 0xffffffffffffffffULL;
+   vex_state->guest_F11  = 0xffffffffffffffffULL;
+   vex_state->guest_F12  = 0xffffffffffffffffULL;
+   vex_state->guest_F13  = 0xffffffffffffffffULL;
+   vex_state->guest_F14  = 0xffffffffffffffffULL;
+   vex_state->guest_F15  = 0xffffffffffffffffULL;
+   vex_state->guest_F16  = 0xffffffffffffffffULL;
+   vex_state->guest_F17  = 0xffffffffffffffffULL;
+   vex_state->guest_F18  = 0xffffffffffffffffULL;
+   vex_state->guest_F19  = 0xffffffffffffffffULL;
+   vex_state->guest_F20  = 0xffffffffffffffffULL;
+   vex_state->guest_F21  = 0xffffffffffffffffULL;
+   vex_state->guest_F22  = 0xffffffffffffffffULL;
+   vex_state->guest_F23  = 0xffffffffffffffffULL;
+   vex_state->guest_F24  = 0xffffffffffffffffULL; /* Static registers */
+   vex_state->guest_F25  = 0xffffffffffffffffULL;
+   vex_state->guest_F26  = 0xffffffffffffffffULL;
+   vex_state->guest_F27  = 0xffffffffffffffffULL;
+   vex_state->guest_F28  = 0xffffffffffffffffULL;
+   vex_state->guest_F29  = 0xffffffffffffffffULL;
+   vex_state->guest_F30  = 0xffffffffffffffffULL;
+   vex_state->guest_F31  = 0xffffffffffffffffULL;
+
+   vex_state->guest_FCC0 = 0; /* Condition Flag Registers */
+   vex_state->guest_FCC1 = 0;
+   vex_state->guest_FCC2 = 0;
+   vex_state->guest_FCC3 = 0;
+   vex_state->guest_FCC4 = 0;
+   vex_state->guest_FCC5 = 0;
+   vex_state->guest_FCC6 = 0;
+   vex_state->guest_FCC7 = 0;
+   vex_state->guest_FCSR = 0; /* FP Control and Status Register */
+
+   /* Various pseudo-regs mandated by Vex or Valgrind. */
+   /* Emulation notes */
+   vex_state->guest_EMNOTE = 0;
+
+   /* For clflush: record start and length of area to invalidate */
+   vex_state->guest_CMSTART = 0;
+   vex_state->guest_CMLEN   = 0;
+
+   /* Used to record the unredirected guest address at the start of
+      a translation whose start has been redirected.  By reading
+      this pseudo-register shortly afterwards, the translation can
+      find out what the corresponding no-redirection address was.
+      Note, this is only set for wrap-style redirects, not for
+      replace-style ones. */
+   vex_state->guest_NRADDR = 0;
+}
+
+
+/*-----------------------------------------------------------*/
+/*--- Describing the loongarch64 guest state, for the     ---*/
+/*--- benefit of iropt and instrumenters                  ---*/
+/*-----------------------------------------------------------*/
+
+/* Figure out if any part of the guest state contained in minoff
+   .. maxoff requires precise memory exceptions.  If in doubt return
+   True (but this generates significantly slower code).
+
+   We enforce precise exns for guest SP, PC and FP.
+
+   Only SP is needed in mode VexRegUpdSpAtMemAccess.
+*/
+
+Bool guest_loongarch64_state_requires_precise_mem_exns ( Int minoff,
+                                                         Int maxoff,
+                                                         VexRegisterUpdates pxControl )
+{
+   Int sp_min = offsetof(VexGuestLOONGARCH64State, guest_R3);
+   Int sp_max = sp_min + 8 - 1;
+   if ( maxoff < sp_min || minoff > sp_max ) {
+      /* no overlap with sp */
+      if (pxControl == VexRegUpdSpAtMemAccess)
+         return False;  /* We only need to check stack pointer. */
+   } else {
+      return True;
+   }
+
+   Int pc_min = offsetof(VexGuestLOONGARCH64State, guest_PC);
+   Int pc_max = pc_min + 8 - 1;
+   if ( maxoff < pc_min || minoff > pc_max ) {
+      /* no overlap with pc */
+   } else {
+      return True;
+   }
+
+   Int fp_min = offsetof(VexGuestLOONGARCH64State, guest_R22);
+   Int fp_max = fp_min + 8 - 1;
+   if ( maxoff < fp_min || minoff > fp_max ) {
+      /* no overlap with fp */
+   } else {
+      return True;
+   }
+
+   return False;
+}
+
+#define ALWAYSDEFD64(field)                            \
+   { offsetof(VexGuestLOONGARCH64State, field),        \
+      (sizeof ((VexGuestLOONGARCH64State*)0)->field) }
+
+VexGuestLayout loongarch64Guest_layout = {
+   /* Total size of the guest state, in bytes. */
+   .total_sizeB = sizeof(VexGuestLOONGARCH64State),
+   /* Describe the stack pointer. */
+   .offset_SP = offsetof(VexGuestLOONGARCH64State, guest_R3),
+   .sizeof_SP = 8,
+   /* Describe the frame pointer. */
+   .offset_FP = offsetof(VexGuestLOONGARCH64State, guest_R22),
+   .sizeof_FP = 8,
+   /* Describe the instruction pointer. */
+   .offset_IP = offsetof(VexGuestLOONGARCH64State, guest_PC),
+   .sizeof_IP = 8,
+   /* Describe any sections to be regarded by Memcheck as
+      'always-defined'. */
+   .n_alwaysDefd = 6,
+   /* ? :(  */
+   .alwaysDefd = {
+                  /* 0 */ ALWAYSDEFD64(guest_R0),
+                  /* 1 */ ALWAYSDEFD64(guest_PC),
+                  /* 2 */ ALWAYSDEFD64(guest_EMNOTE),
+                  /* 3 */ ALWAYSDEFD64(guest_CMSTART),
+                  /* 4 */ ALWAYSDEFD64(guest_CMLEN),
+                  /* 5 */ ALWAYSDEFD64(guest_NRADDR),
+                  }
+};
+
+
+/*---------------------------------------------------------------*/
+/*--- end                         guest_loongarch64_helpers.c ---*/
+/*---------------------------------------------------------------*/
diff --git a/VEX/priv/guest_loongarch64_toIR.c b/VEX/priv/guest_loongarch64_toIR.c
new file mode 100644
index 000000000..ff41d13f4
--- /dev/null
+++ b/VEX/priv/guest_loongarch64_toIR.c
@@ -0,0 +1,504 @@
+
+/*--------------------------------------------------------------------*/
+/*--- begin                               guest_loongarch64_toIR.c ---*/
+/*--------------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+*/
+
+/* Translates LOONGARCH64 code to IR. */
+
+#include "libvex_basictypes.h"
+#include "libvex_ir.h"
+#include "libvex.h"
+#include "libvex_guest_loongarch64.h"
+
+#include "main_util.h"
+#include "main_globals.h"
+#include "guest_generic_bb_to_IR.h"
+#include "guest_loongarch64_defs.h"
+
+
+/*------------------------------------------------------------*/
+/*--- Globals                                              ---*/
+/*------------------------------------------------------------*/
+
+/* These are set at the start of the translation of a instruction, so
+   that we don't have to pass them around endlessly.  CONST means does
+   not change during translation of the instruction. */
+
+/* CONST: what is the host's endianness?  We need to know this in
+   order to do sub-register accesses to the SIMD/FP registers
+   correctly. */
+static VexEndness host_endness;
+
+/* CONST: The guest address for the instruction currently being
+   translated.  */
+static Addr64 guest_PC_curr_instr;
+
+/* MOD: The IRSB* into which we're generating code. */
+static IRSB* irsb;
+
+
+/*------------------------------------------------------------*/
+/*--- Debugging output                                     ---*/
+/*------------------------------------------------------------*/
+
+#define DIP(format, args...)           \
+   if (vex_traceflags & VEX_TRACE_FE)  \
+      vex_printf(format, ## args)
+
+static const HChar* nameIReg( UInt reg )
+{
+   vassert(reg < 32);
+   static const HChar* reg_names[32] = {
+      "$zero",
+      "$ra",
+      "$tp",
+      "$sp",
+      "$a0", "$a1", "$a2", "$a3", "$a4", "$a5", "$a6", "$a7",
+      "$t0", "$t1", "$t2", "$t3", "$t4", "$t5", "$t6", "$t7", "$t8",
+      "$r21", /* Reserved */
+      "$fp",
+      "$s0", "$s1", "$s2", "$s3", "$s4", "$s5", "$s6", "$s7", "$s8"
+   };
+   return reg_names[reg];
+}
+
+static const HChar* nameFReg( UInt reg )
+{
+   vassert(reg < 32);
+   static const HChar* reg_names[32] = {
+      "$fa0",  "$fa1",  "$fa2",  "$fa3",  "$fa4",  "$fa5",  "$fa6",  "$fa7",
+      "$ft0",  "$ft1",  "$ft2",  "$ft3",  "$ft4",  "$ft5",  "$ft6",  "$ft7",
+      "$ft8",  "$ft9",  "$ft10", "$ft11", "$ft12", "$ft13", "$ft14", "$ft15",
+      "$fs0",  "$fs1",  "$fs2",  "$fs3",  "$fs4",  "$fs5",  "$fs6",  "$fs7"
+   };
+   return reg_names[reg];
+}
+
+static const HChar* nameFCC( UInt reg )
+{
+   vassert(reg < 8);
+   static const HChar* reg_names[8] = {
+      "$fcc0", "$fcc1", "$fcc2", "$fcc3", "$fcc4", "$fcc5", "$fcc6", "$fcc7"
+   };
+   return reg_names[reg];
+}
+
+static const HChar* nameFCSR( UInt reg )
+{
+   vassert(reg < 4);
+   static const HChar* reg_names[4] = {
+      "$fcsr0", "$fcsr1", "$fcsr2", "$fcsr3"
+   };
+   return reg_names[reg];
+}
+
+
+/*------------------------------------------------------------*/
+/*--- Helper bits and pieces for deconstructing the        ---*/
+/*--- loongarch64 insn stream.                             ---*/
+/*------------------------------------------------------------*/
+
+/* Get insn[max:min] */
+#define SLICE(insn, max, min) \
+   ((((UInt)(insn)) >> (min)) & (UInt)((1ULL << ((max) - (min) + 1)) - 1ULL))
+
+/* Do a little-endian load of a 32-bit word, regardless of the
+   endianness of the underlying host. */
+static inline UInt getUInt ( const UChar* p )
+{
+   UInt w = 0;
+   w = (w << 8) | p[3];
+   w = (w << 8) | p[2];
+   w = (w << 8) | p[1];
+   w = (w << 8) | p[0];
+   return w;
+}
+
+
+/*------------------------------------------------------------*/
+/*--- Helper bits and pieces for creating IR fragments.    ---*/
+/*------------------------------------------------------------*/
+
+static inline IRExpr* mkU64 ( ULong i )
+{
+   return IRExpr_Const(IRConst_U64(i));
+}
+
+static inline IRExpr* mkU32 ( UInt i )
+{
+   return IRExpr_Const(IRConst_U32(i));
+}
+
+static inline IRExpr* mkU16 ( UInt i )
+{
+   vassert(i < 65536);
+   return IRExpr_Const(IRConst_U16(i));
+}
+
+static inline IRExpr* mkU8 ( UInt i )
+{
+   vassert(i < 256);
+   return IRExpr_Const(IRConst_U8((UChar)i));
+}
+
+static inline IRExpr* mkU1 ( UInt i )
+{
+   vassert(i == 0 || i == 1);
+   return IRExpr_Const(IRConst_U1((Bool)i));
+}
+
+static inline IRExpr* mkF64i ( ULong i )
+{
+   return IRExpr_Const(IRConst_F64i(i));
+}
+
+static inline IRExpr* mkF32i ( UInt i )
+{
+   return IRExpr_Const(IRConst_F32i(i));
+}
+
+static inline IRExpr* mkexpr ( IRTemp tmp )
+{
+   return IRExpr_RdTmp(tmp);
+}
+
+static inline IRExpr* unop ( IROp op, IRExpr* a )
+{
+   return IRExpr_Unop(op, a);
+}
+
+static inline IRExpr* binop ( IROp op, IRExpr* a1, IRExpr* a2 )
+{
+   return IRExpr_Binop(op, a1, a2);
+}
+
+static inline IRExpr* triop ( IROp op, IRExpr* a1, IRExpr* a2, IRExpr* a3 )
+{
+   return IRExpr_Triop(op, a1, a2, a3);
+}
+
+static inline IRExpr* qop ( IROp op, IRExpr* a1, IRExpr* a2,
+                            IRExpr* a3, IRExpr* a4 )
+{
+   return IRExpr_Qop(op, a1, a2, a3, a4);
+}
+
+static inline IRExpr* load ( IRType ty, IRExpr* addr )
+{
+   return IRExpr_Load(Iend_LE, ty, addr);
+}
+
+/* Add a statement to the list held by "irbb". */
+static inline void stmt ( IRStmt* st )
+{
+   addStmtToIRSB(irsb, st);
+}
+
+static inline void store ( IRExpr* addr, IRExpr* data )
+{
+   stmt(IRStmt_Store(Iend_LE, addr, data));
+}
+
+static inline void assign ( IRTemp dst, IRExpr* e )
+{
+   stmt(IRStmt_WrTmp(dst, e));
+}
+
+static inline void exit ( IRExpr* e, IRJumpKind jk, ULong offs )
+{
+   stmt(IRStmt_Exit(e, jk, IRConst_U64(guest_PC_curr_instr + offs),
+                    offsetof(VexGuestLOONGARCH64State, guest_PC)));
+}
+
+/* Generate an expression to check if addr is aligned. */
+static inline IRExpr* check_align ( IRExpr* addr, IRExpr* align )
+{
+   return binop(Iop_CmpNE64, binop(Iop_And64, addr, align),
+                IRExpr_Get(offsetof(VexGuestLOONGARCH64State, guest_R0),
+                           Ity_I64));
+}
+
+/* Generate a SIGSYS if the expression evaluates to true. */
+static inline void gen_SIGSYS ( IRExpr* cond )
+{
+   exit(cond, Ijk_SigSYS, 4);
+}
+
+static inline void cas ( IRTemp old, IRExpr* addr, IRExpr* expd, IRExpr* new )
+{
+   IRCAS* c = mkIRCAS(IRTemp_INVALID, old, Iend_LE, addr,
+                      NULL, expd, NULL, new);
+   stmt(IRStmt_CAS(c));
+}
+
+/* Generate a new temporary of the given type. */
+static inline IRTemp newTemp ( IRType ty )
+{
+   vassert(isPlausibleIRType(ty));
+   return newIRTemp(irsb->tyenv, ty);
+}
+
+/* S-extend 8/16/32 bit int expr to 64. */
+static IRExpr* extendS ( IRType ty, IRExpr* e )
+{
+   switch (ty) {
+      case Ity_I1:  return unop(Iop_1Sto64, e);
+      case Ity_I8:  return unop(Iop_8Sto64, e);
+      case Ity_I16: return unop(Iop_16Sto64, e);
+      case Ity_I32: return unop(Iop_32Sto64, e);
+      default: vassert(0);
+   }
+}
+
+/* Z-extend 8/16/32 bit int expr to 64. */
+static IRExpr* extendU ( IRType ty, IRExpr* e )
+{
+   switch (ty) {
+      case Ity_I1:  return unop(Iop_1Uto64, e);
+      case Ity_I8:  return unop(Iop_8Uto64, e);
+      case Ity_I16: return unop(Iop_16Uto64, e);
+      case Ity_I32: return unop(Iop_32Uto64, e);
+      default: vassert(0);
+   }
+}
+
+
+/*------------------------------------------------------------*/
+/*--- Helpers for accessing guest registers.               ---*/
+/*------------------------------------------------------------*/
+
+/* ---------------- Integer registers ---------------- */
+
+static Int offsetIReg ( UInt iregNo )
+{
+   switch (iregNo) {
+      case 0:  return offsetof(VexGuestLOONGARCH64State, guest_R0);
+      case 1:  return offsetof(VexGuestLOONGARCH64State, guest_R1);
+      case 2:  return offsetof(VexGuestLOONGARCH64State, guest_R2);
+      case 3:  return offsetof(VexGuestLOONGARCH64State, guest_R3);
+      case 4:  return offsetof(VexGuestLOONGARCH64State, guest_R4);
+      case 5:  return offsetof(VexGuestLOONGARCH64State, guest_R5);
+      case 6:  return offsetof(VexGuestLOONGARCH64State, guest_R6);
+      case 7:  return offsetof(VexGuestLOONGARCH64State, guest_R7);
+      case 8:  return offsetof(VexGuestLOONGARCH64State, guest_R8);
+      case 9:  return offsetof(VexGuestLOONGARCH64State, guest_R9);
+      case 10: return offsetof(VexGuestLOONGARCH64State, guest_R10);
+      case 11: return offsetof(VexGuestLOONGARCH64State, guest_R11);
+      case 12: return offsetof(VexGuestLOONGARCH64State, guest_R12);
+      case 13: return offsetof(VexGuestLOONGARCH64State, guest_R13);
+      case 14: return offsetof(VexGuestLOONGARCH64State, guest_R14);
+      case 15: return offsetof(VexGuestLOONGARCH64State, guest_R15);
+      case 16: return offsetof(VexGuestLOONGARCH64State, guest_R16);
+      case 17: return offsetof(VexGuestLOONGARCH64State, guest_R17);
+      case 18: return offsetof(VexGuestLOONGARCH64State, guest_R18);
+      case 19: return offsetof(VexGuestLOONGARCH64State, guest_R19);
+      case 20: return offsetof(VexGuestLOONGARCH64State, guest_R20);
+      case 21: return offsetof(VexGuestLOONGARCH64State, guest_R21);
+      case 22: return offsetof(VexGuestLOONGARCH64State, guest_R22);
+      case 23: return offsetof(VexGuestLOONGARCH64State, guest_R23);
+      case 24: return offsetof(VexGuestLOONGARCH64State, guest_R24);
+      case 25: return offsetof(VexGuestLOONGARCH64State, guest_R25);
+      case 26: return offsetof(VexGuestLOONGARCH64State, guest_R26);
+      case 27: return offsetof(VexGuestLOONGARCH64State, guest_R27);
+      case 28: return offsetof(VexGuestLOONGARCH64State, guest_R28);
+      case 29: return offsetof(VexGuestLOONGARCH64State, guest_R29);
+      case 30: return offsetof(VexGuestLOONGARCH64State, guest_R30);
+      case 31: return offsetof(VexGuestLOONGARCH64State, guest_R31);
+      default: vassert(0);
+   }
+}
+
+static IRExpr* getIReg8 ( UInt iregNo )
+{
+   return IRExpr_Get(offsetIReg(iregNo), Ity_I8);
+}
+
+static IRExpr* getIReg16 ( UInt iregNo )
+{
+   return IRExpr_Get(offsetIReg(iregNo), Ity_I16);
+}
+
+static IRExpr* getIReg32 ( UInt iregNo )
+{
+   return IRExpr_Get(offsetIReg(iregNo), Ity_I32);
+}
+
+static IRExpr* getIReg64 ( UInt iregNo )
+{
+   return IRExpr_Get(offsetIReg(iregNo), Ity_I64);
+}
+
+static void putIReg ( UInt iregNo, IRExpr* e )
+{
+   vassert(typeOfIRExpr(irsb->tyenv, e) == Ity_I64);
+   if (iregNo != 0) /* $r0 - constant zero */
+      stmt(IRStmt_Put(offsetIReg(iregNo), e));
+}
+
+static void putPC ( IRExpr* e )
+{
+   vassert(typeOfIRExpr(irsb->tyenv, e) == Ity_I64);
+   stmt(IRStmt_Put(offsetof(VexGuestLOONGARCH64State, guest_PC), e));
+}
+
+
+/*------------------------------------------------------------*/
+/*--- Disassemble a single LOONGARCH64 instruction         ---*/
+/*------------------------------------------------------------*/
+
+/* Disassemble a single LOONGARCH64 instruction into IR.  The instruction
+   has is located at |guest_instr| and has guest IP of |guest_PC_curr_instr|,
+   which will have been set before the call here.  Returns True iff the
+   instruction was decoded, in which case *dres will be set accordingly,
+   or False, in which case *dres should be ignored by the caller. */
+
+static Bool disInstr_LOONGARCH64_WRK_special ( DisResult* dres,
+                                               const UChar* guest_instr )
+{
+   return False;
+}
+
+static Bool disInstr_LOONGARCH64_WRK ( /*MB_OUT*/DisResult* dres,
+                                       const UChar* guest_instr,
+                                       const VexArchInfo* archinfo,
+                                       const VexAbiInfo*  abiinfo,
+                                       Bool sigill_diag )
+{
+   /* Set result defaults. */
+   dres->whatNext    = Dis_Continue;
+   dres->len         = 4;
+   dres->jk_StopHere = Ijk_INVALID;
+   dres->hint        = Dis_HintNone;
+
+   /* At least this is simple on LOONGARCH64: insns are all 4 bytes long,
+      and 4-aligned.  So just fish the whole thing out of memory right now
+      and have done. */
+   UInt insn = getUInt(guest_instr);
+   DIP("\t0x%llx:\t0x%08x\t", (Addr64)guest_PC_curr_instr, insn);
+   vassert((guest_PC_curr_instr & 3ULL) == 0);
+
+   /* Spot "Special" instructions (see comment at top of file). */
+   Bool ok = disInstr_LOONGARCH64_WRK_special(dres, guest_instr);
+   if (ok)
+      return ok;
+
+   /* Main LOONGARCH64 instruction decoder starts here. */
+   switch (SLICE(insn, 31, 30)) {
+      default:
+         ok = False;
+         break;
+   }
+
+   /* If the next-level down decoders failed, make sure |dres| didn't
+      get changed. */
+   if (!ok) {
+      vassert(dres->whatNext    == Dis_Continue);
+      vassert(dres->len         == 4);
+      vassert(dres->jk_StopHere == Ijk_INVALID);
+   }
+   return ok;
+}
+
+
+/*------------------------------------------------------------*/
+/*--- Top-level fn                                         ---*/
+/*------------------------------------------------------------*/
+
+/* Disassemble a single instruction into IR.  The instruction
+   is located in host memory at &guest_code[delta]. */
+
+DisResult disInstr_LOONGARCH64 ( IRSB*              irsb_IN,
+                                 const UChar*       guest_code_IN,
+                                 Long               delta_IN,
+                                 Addr               guest_IP,
+                                 VexArch            guest_arch,
+                                 const VexArchInfo* archinfo,
+                                 const VexAbiInfo*  abiinfo,
+                                 VexEndness         host_endness_IN,
+                                 Bool               sigill_diag_IN )
+{
+   DisResult dres;
+   vex_bzero(&dres, sizeof(dres));
+
+   /* Set globals (see top of this file) */
+   vassert(guest_arch == VexArchLOONGARCH64);
+
+   irsb                = irsb_IN;
+   host_endness        = host_endness_IN;
+   guest_PC_curr_instr = (Addr64)guest_IP;
+
+   /* Try to decode */
+   Bool ok = disInstr_LOONGARCH64_WRK(&dres,
+                                      &guest_code_IN[delta_IN],
+                                      archinfo, abiinfo, sigill_diag_IN);
+
+   if (ok) {
+      /* All decode successes end up here. */
+      vassert(dres.len == 4);
+      switch (dres.whatNext) {
+         case Dis_Continue:
+            putPC(mkU64(dres.len + guest_PC_curr_instr));
+            break;
+         case Dis_StopHere:
+            break;
+         default:
+            vassert(0);
+            break;
+      }
+      DIP("\n");
+   } else {
+      /* All decode failures end up here. */
+      if (sigill_diag_IN) {
+         Int   i, j;
+         UChar buf[64];
+         UInt  insn = getUInt(&guest_code_IN[delta_IN]);
+         vex_bzero(buf, sizeof(buf));
+         for (i = j = 0; i < 32; i++) {
+            if (i > 0 && (i & 3) == 0)
+               buf[j++] = ' ';
+            buf[j++] = (insn & (1 << (31 - i))) ? '1' : '0';
+         }
+         vex_printf("disInstr(loongarch64): unhandled instruction 0x%08x\n", insn);
+         vex_printf("disInstr(loongarch64): %s\n", buf);
+      }
+
+      /* Tell the dispatcher that this insn cannot be decoded, and so
+         has not been executed, and (is currently) the next to be
+         executed.  PC should be up-to-date since it is made so at the
+         start of each insn, but nevertheless be paranoid and update
+         it again right now. */
+      putPC(mkU64(guest_PC_curr_instr));
+      dres.len         = 0;
+      dres.whatNext    = Dis_StopHere;
+      dres.jk_StopHere = Ijk_NoDecode;
+   }
+
+   return dres;
+}
+
+
+/*--------------------------------------------------------------------*/
+/*--- end                                 guest_loongarch64_toIR.c ---*/
+/*--------------------------------------------------------------------*/
diff --git a/VEX/priv/host_loongarch64_defs.c b/VEX/priv/host_loongarch64_defs.c
new file mode 100644
index 000000000..e1068f3a6
--- /dev/null
+++ b/VEX/priv/host_loongarch64_defs.c
@@ -0,0 +1,362 @@
+
+/*---------------------------------------------------------------*/
+/*--- begin                           host_loongarch64_defs.c ---*/
+/*---------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+*/
+
+#include "libvex_basictypes.h"
+#include "libvex.h"
+#include "libvex_trc_values.h"
+
+#include "main_util.h"
+#include "host_generic_regs.h"
+#include "host_loongarch64_defs.h"
+
+
+/* --------- Local helpers. --------- */
+
+static inline void mapReg ( HRegRemap* m, HReg* r )
+{
+   *r = lookupHRegRemap(m, *r);
+}
+
+static inline Int extend ( UInt imm, UInt size )
+{
+   UInt shift = 32 - size;
+   return (((Int)imm << shift) >> shift);
+}
+
+
+/* --------- Registers. --------- */
+
+const RRegUniverse* getRRegUniverse_LOONGARCH64 ( void )
+{
+   /* The real-register universe is a big constant, so we just want to
+      initialise it once. */
+   static RRegUniverse rRegUniverse_LOONGARCH64;
+   static Bool         rRegUniverse_LOONGARCH64_initted = False;
+
+   /* Handy shorthand, nothing more */
+   RRegUniverse* ru = &rRegUniverse_LOONGARCH64;
+
+   /* This isn't thread-safe.  Sigh. */
+   if (LIKELY(rRegUniverse_LOONGARCH64_initted == True))
+      return ru;
+
+   RRegUniverse__init(ru);
+
+   /* Add the registers.  The initial segment of this array must be
+      those available for allocation by reg-alloc, and those that
+      follow are not available for allocation. */
+   ru->allocable_start[HRcInt64] = ru->size;
+   ru->regs[ru->size++] = hregLOONGARCH64_R23();
+   ru->regs[ru->size++] = hregLOONGARCH64_R24();
+   ru->regs[ru->size++] = hregLOONGARCH64_R25();
+   ru->regs[ru->size++] = hregLOONGARCH64_R26();
+   ru->regs[ru->size++] = hregLOONGARCH64_R27();
+   ru->regs[ru->size++] = hregLOONGARCH64_R28();
+   ru->regs[ru->size++] = hregLOONGARCH64_R29();
+   ru->regs[ru->size++] = hregLOONGARCH64_R30();
+   // $r31 is used as guest stack pointer, not available to regalloc.
+
+   // $r12 is used as a chaining/spill/ProfInc temporary
+   // $r13 is used as a ProfInc temporary
+   ru->regs[ru->size++] = hregLOONGARCH64_R14();
+   ru->regs[ru->size++] = hregLOONGARCH64_R15();
+   ru->regs[ru->size++] = hregLOONGARCH64_R16();
+   ru->regs[ru->size++] = hregLOONGARCH64_R17();
+   ru->regs[ru->size++] = hregLOONGARCH64_R18();
+   ru->regs[ru->size++] = hregLOONGARCH64_R19();
+   ru->regs[ru->size++] = hregLOONGARCH64_R20();
+   ru->allocable_end[HRcInt64] = ru->size - 1;
+
+   ru->allocable_start[HRcFlt64] = ru->size;
+   ru->regs[ru->size++] = hregLOONGARCH64_F24();
+   ru->regs[ru->size++] = hregLOONGARCH64_F25();
+   ru->regs[ru->size++] = hregLOONGARCH64_F26();
+   ru->regs[ru->size++] = hregLOONGARCH64_F27();
+   ru->regs[ru->size++] = hregLOONGARCH64_F28();
+   ru->regs[ru->size++] = hregLOONGARCH64_F29();
+   ru->regs[ru->size++] = hregLOONGARCH64_F30();
+   ru->regs[ru->size++] = hregLOONGARCH64_F31();
+   ru->allocable_end[HRcFlt64] = ru->size - 1;
+
+   ru->allocable = ru->size;
+
+   /* And other regs, not available to the allocator. */
+   ru->regs[ru->size++] = hregLOONGARCH64_R0();
+   ru->regs[ru->size++] = hregLOONGARCH64_R1();
+   ru->regs[ru->size++] = hregLOONGARCH64_R2();
+   ru->regs[ru->size++] = hregLOONGARCH64_R3();
+   ru->regs[ru->size++] = hregLOONGARCH64_R4();
+   ru->regs[ru->size++] = hregLOONGARCH64_R5();
+   ru->regs[ru->size++] = hregLOONGARCH64_R6();
+   ru->regs[ru->size++] = hregLOONGARCH64_R7();
+   ru->regs[ru->size++] = hregLOONGARCH64_R8();
+   ru->regs[ru->size++] = hregLOONGARCH64_R9();
+   ru->regs[ru->size++] = hregLOONGARCH64_R10();
+   ru->regs[ru->size++] = hregLOONGARCH64_R11();
+   ru->regs[ru->size++] = hregLOONGARCH64_R12();
+   ru->regs[ru->size++] = hregLOONGARCH64_R13();
+   ru->regs[ru->size++] = hregLOONGARCH64_R21();
+   ru->regs[ru->size++] = hregLOONGARCH64_R22();
+   ru->regs[ru->size++] = hregLOONGARCH64_R31();
+   ru->regs[ru->size++] = hregLOONGARCH64_FCSR3();
+
+   rRegUniverse_LOONGARCH64_initted = True;
+
+   RRegUniverse__check_is_sane(ru);
+   return ru;
+}
+
+UInt ppHRegLOONGARCH64 ( HReg reg )
+{
+   Int r;
+   Int ret = 0;
+   static const HChar* ireg_names[32] = {
+      "$zero",
+      "$ra",
+      "$tp",
+      "$sp",
+      "$a0", "$a1", "$a2", "$a3", "$a4", "$a5", "$a6", "$a7",
+      "$t0", "$t1", "$t2", "$t3", "$t4", "$t5", "$t6", "$t7", "$t8",
+      "$r21", /* Reserved */
+      "$fp",
+      "$s0", "$s1", "$s2", "$s3", "$s4", "$s5", "$s6", "$s7", "$s8"
+   };
+   static const HChar* freg_names[32] = {
+      "$fa0",  "$fa1",  "$fa2",  "$fa3",  "$fa4",  "$fa5",  "$fa6",  "$fa7",
+      "$ft0",  "$ft1",  "$ft2",  "$ft3",  "$ft4",  "$ft5",  "$ft6",  "$ft7",
+      "$ft8",  "$ft9",  "$ft10", "$ft11", "$ft12", "$ft13", "$ft14", "$ft15",
+      "$fs0",  "$fs1",  "$fs2",  "$fs3",  "$fs4",  "$fs5",  "$fs6",  "$fs7"
+   };
+
+   /* Be generic for all virtual regs. */
+   if (hregIsVirtual(reg)) {
+      return ppHReg(reg);
+   }
+
+   /* But specific for real regs. */
+   switch (hregClass(reg)) {
+      case HRcInt32:
+         r = hregEncoding(reg);
+         vassert(r >= 0 && r < 4);
+         ret = vex_printf("$fcsr%d", r);
+         break;
+      case HRcInt64:
+         r = hregEncoding(reg);
+         vassert(r >= 0 && r < 32);
+         ret = vex_printf("%s", ireg_names[r]);
+         break;
+      case HRcFlt64:
+         r = hregEncoding(reg);
+         vassert(r >= 0 && r < 32);
+         ret = vex_printf("%s", freg_names[r]);
+         break;
+      default:
+         vpanic("ppHRegLOONGARCH64");
+         break;
+   }
+
+   return ret;
+}
+
+
+/* -------- Pretty Print instructions ------------- */
+
+void ppLOONGARCH64Instr ( const LOONGARCH64Instr* i, Bool mode64 )
+{
+   vassert(mode64 == True);
+   switch (i->tag) {
+      default:
+         vpanic("ppLOONGARCH64Instr");
+         break;
+   }
+}
+
+
+/* --------- Helpers for register allocation. --------- */
+
+void getRegUsage_LOONGARCH64Instr ( HRegUsage* u, const LOONGARCH64Instr* i,
+                                    Bool mode64 )
+{
+   vassert(mode64 == True);
+   initHRegUsage(u);
+   switch (i->tag) {
+      default:
+         ppLOONGARCH64Instr(i, mode64);
+         vpanic("getRegUsage_LOONGARCH64Instr");
+         break;
+   }
+}
+
+void mapRegs_LOONGARCH64Instr ( HRegRemap* m, LOONGARCH64Instr* i,
+                                Bool mode64 )
+{
+   vassert(mode64 == True);
+   switch (i->tag) {
+      default:
+         ppLOONGARCH64Instr(i, mode64);
+         vpanic("mapRegs_LOONGARCH64Instr");
+         break;
+   }
+}
+
+/* Generate loongarch64 spill instructions under the direction of the
+   register allocator. */
+void genSpill_LOONGARCH64 ( /*OUT*/ HInstr** i1, /*OUT*/ HInstr** i2,
+                            HReg rreg, Int offsetB, Bool mode64 )
+{
+   vassert(mode64 == True);
+   vassert(offsetB >= 0);
+   vassert(!hregIsVirtual(rreg));
+
+   switch (hregClass(rreg)) {
+      default:
+         ppHRegClass(hregClass(rreg));
+         vpanic("genSpill_LOONGARCH64: unimplemented regclass");
+         break;
+   }
+}
+
+/* Generate loongarch64 reload instructions under the direction of the
+   register allocator. */
+void genReload_LOONGARCH64 ( /*OUT*/ HInstr** i1, /*OUT*/ HInstr** i2,
+                             HReg rreg, Int offsetB, Bool mode64 )
+{
+   vassert(mode64 == True);
+   vassert(offsetB >= 0);
+   vassert(!hregIsVirtual(rreg));
+
+   switch (hregClass(rreg)) {
+      default:
+         ppHRegClass(hregClass(rreg));
+         vpanic("genReload_LOONGARCH64: unimplemented regclass");
+         break;
+   }
+}
+
+/* Generate loongarch64 move instructions under the direction of the
+   register allocator. */
+LOONGARCH64Instr* genMove_LOONGARCH64 ( HReg from, HReg to, Bool mode64 )
+{
+   vassert(mode64 == True);
+   switch (hregClass(from)) {
+      default:
+         ppHRegClass(hregClass(from));
+         vpanic("genMove_LOONGARCH64: unimplemented regclass");
+   }
+}
+
+
+/* --------- The loongarch64 assembler --------- */
+
+/* Emit an instruction into buf and return the number of bytes used.
+   Note that buf is not the insn's final place, and therefore it is
+   imperative to emit position-independent code.  If the emitted
+   instruction was a profiler inc, set *is_profInc to True, else
+   leave it unchanged. */
+Int emit_LOONGARCH64Instr ( /*MB_MOD*/Bool* is_profInc,
+                            UChar* buf,
+                            Int nbuf,
+                            const LOONGARCH64Instr* i,
+                            Bool mode64,
+                            VexEndness endness_host,
+                            const void* disp_cp_chain_me_to_slowEP,
+                            const void* disp_cp_chain_me_to_fastEP,
+                            const void* disp_cp_xindir,
+                            const void* disp_cp_xassisted )
+{
+   vassert(mode64 == True);
+
+   UInt* p = (UInt*)buf;
+   vassert(nbuf >= 32);
+   vassert((((HWord)buf) & 3) == 0);
+
+   switch (i->tag) {
+      default:
+         p = NULL;
+         break;
+   }
+
+   if (p == NULL) {
+      ppLOONGARCH64Instr(i, True);
+      vpanic("emit_LOONGARCH64Instr");
+      /*NOTREACHED*/
+   }
+
+   vassert(((UChar*)p) - &buf[0] <= 48);
+   return ((UChar*)p) - &buf[0];
+}
+
+/* How big is an event check?  See case for mkEvCheck just above.  That
+   crosschecks what this returns, so we can tell if we're inconsistent. */
+Int evCheckSzB_LOONGARCH64 ( void )
+{
+   return 0;
+}
+
+/* NB: what goes on here has to be very closely coordinated with the
+   emitInstr case for XDirect, above. */
+VexInvalRange chainXDirect_LOONGARCH64 ( VexEndness endness_host,
+                                         void* place_to_chain,
+                                         const void* disp_cp_chain_me_EXPECTED,
+                                         const void* place_to_jump_to )
+{
+   vassert(endness_host == VexEndnessLE);
+
+   VexInvalRange vir = { (HWord)place_to_chain, 0 };
+   return vir;
+}
+
+/* NB: what goes on here has to be very closely coordinated with the
+   emitInstr case for XDirect, above. */
+VexInvalRange unchainXDirect_LOONGARCH64 ( VexEndness endness_host,
+                                           void* place_to_unchain,
+                                           const void* place_to_jump_to_EXPECTED,
+                                           const void* disp_cp_chain_me )
+{
+   vassert(endness_host == VexEndnessLE);
+
+   VexInvalRange vir = { (HWord)place_to_unchain, 0 };
+   return vir;
+}
+
+/* Patch the counter address into a profile inc point, as previously
+   created by the mkProfInc. */
+VexInvalRange patchProfInc_LOONGARCH64 ( VexEndness endness_host,
+                                         void*  place_to_patch,
+                                         const ULong* location_of_counter )
+{
+   vassert(endness_host == VexEndnessLE);
+   vassert(sizeof(ULong*) == 8);
+
+   VexInvalRange vir = { (HWord)place_to_patch, 0 };
+   return vir;
+}
+
+
+/*---------------------------------------------------------------*/
+/*--- end                             host_loongarch64_defs.c ---*/
+/*---------------------------------------------------------------*/
diff --git a/VEX/priv/host_loongarch64_defs.h b/VEX/priv/host_loongarch64_defs.h
new file mode 100644
index 000000000..e76d89876
--- /dev/null
+++ b/VEX/priv/host_loongarch64_defs.h
@@ -0,0 +1,190 @@
+
+/*---------------------------------------------------------------*/
+/*--- begin                           host_loongarch64_defs.h ---*/
+/*---------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+*/
+
+#ifndef __VEX_HOST_LOONGARCH64_DEFS_H
+#define __VEX_HOST_LOONGARCH64_DEFS_H
+
+#include "libvex_basictypes.h"
+#include "libvex.h"             /* VexArch */
+#include "host_generic_regs.h"  /* HReg */
+
+
+/* --------- Registers. --------- */
+
+#define ST_IN static inline
+
+/* Integer static registers */
+ST_IN HReg hregLOONGARCH64_R23 ( void ) { return mkHReg(False, HRcInt64, 23,  0); }
+ST_IN HReg hregLOONGARCH64_R24 ( void ) { return mkHReg(False, HRcInt64, 24,  1); }
+ST_IN HReg hregLOONGARCH64_R25 ( void ) { return mkHReg(False, HRcInt64, 25,  2); }
+ST_IN HReg hregLOONGARCH64_R26 ( void ) { return mkHReg(False, HRcInt64, 26,  3); }
+ST_IN HReg hregLOONGARCH64_R27 ( void ) { return mkHReg(False, HRcInt64, 27,  4); }
+ST_IN HReg hregLOONGARCH64_R28 ( void ) { return mkHReg(False, HRcInt64, 28,  5); }
+ST_IN HReg hregLOONGARCH64_R29 ( void ) { return mkHReg(False, HRcInt64, 29,  6); }
+ST_IN HReg hregLOONGARCH64_R30 ( void ) { return mkHReg(False, HRcInt64, 30,  7); }
+/* $r31 is used as guest stack pointer */
+
+/* Integer temporary registers */
+/* $r12 is used as a chaining/ProfInc/Cmove temporary */
+/* $r13 is used as a ProfInc temporary */
+ST_IN HReg hregLOONGARCH64_R14 ( void ) { return mkHReg(False, HRcInt64, 14,  8); }
+ST_IN HReg hregLOONGARCH64_R15 ( void ) { return mkHReg(False, HRcInt64, 15,  9); }
+ST_IN HReg hregLOONGARCH64_R16 ( void ) { return mkHReg(False, HRcInt64, 16, 10); }
+ST_IN HReg hregLOONGARCH64_R17 ( void ) { return mkHReg(False, HRcInt64, 17, 11); }
+ST_IN HReg hregLOONGARCH64_R18 ( void ) { return mkHReg(False, HRcInt64, 18, 12); }
+ST_IN HReg hregLOONGARCH64_R19 ( void ) { return mkHReg(False, HRcInt64, 19, 13); }
+ST_IN HReg hregLOONGARCH64_R20 ( void ) { return mkHReg(False, HRcInt64, 20, 14); }
+
+/* Floating point static registers */
+ST_IN HReg hregLOONGARCH64_F24 ( void ) { return mkHReg(False, HRcFlt64, 24, 15); }
+ST_IN HReg hregLOONGARCH64_F25 ( void ) { return mkHReg(False, HRcFlt64, 25, 16); }
+ST_IN HReg hregLOONGARCH64_F26 ( void ) { return mkHReg(False, HRcFlt64, 26, 17); }
+ST_IN HReg hregLOONGARCH64_F27 ( void ) { return mkHReg(False, HRcFlt64, 27, 18); }
+ST_IN HReg hregLOONGARCH64_F28 ( void ) { return mkHReg(False, HRcFlt64, 28, 19); }
+ST_IN HReg hregLOONGARCH64_F29 ( void ) { return mkHReg(False, HRcFlt64, 29, 20); }
+ST_IN HReg hregLOONGARCH64_F30 ( void ) { return mkHReg(False, HRcFlt64, 30, 21); }
+ST_IN HReg hregLOONGARCH64_F31 ( void ) { return mkHReg(False, HRcFlt64, 31, 22); }
+
+/* Other Integer registers */
+ST_IN HReg hregLOONGARCH64_R0  ( void ) { return mkHReg(False, HRcInt64,  0, 23); }
+ST_IN HReg hregLOONGARCH64_R1  ( void ) { return mkHReg(False, HRcInt64,  1, 24); }
+ST_IN HReg hregLOONGARCH64_R2  ( void ) { return mkHReg(False, HRcInt64,  2, 25); }
+ST_IN HReg hregLOONGARCH64_R3  ( void ) { return mkHReg(False, HRcInt64,  3, 26); }
+ST_IN HReg hregLOONGARCH64_R4  ( void ) { return mkHReg(False, HRcInt64,  4, 27); }
+ST_IN HReg hregLOONGARCH64_R5  ( void ) { return mkHReg(False, HRcInt64,  5, 28); }
+ST_IN HReg hregLOONGARCH64_R6  ( void ) { return mkHReg(False, HRcInt64,  6, 29); }
+ST_IN HReg hregLOONGARCH64_R7  ( void ) { return mkHReg(False, HRcInt64,  7, 30); }
+ST_IN HReg hregLOONGARCH64_R8  ( void ) { return mkHReg(False, HRcInt64,  8, 31); }
+ST_IN HReg hregLOONGARCH64_R9  ( void ) { return mkHReg(False, HRcInt64,  9, 32); }
+ST_IN HReg hregLOONGARCH64_R10 ( void ) { return mkHReg(False, HRcInt64, 10, 33); }
+ST_IN HReg hregLOONGARCH64_R11 ( void ) { return mkHReg(False, HRcInt64, 11, 34); }
+ST_IN HReg hregLOONGARCH64_R12 ( void ) { return mkHReg(False, HRcInt64, 12, 35); }
+ST_IN HReg hregLOONGARCH64_R13 ( void ) { return mkHReg(False, HRcInt64, 13, 36); }
+ST_IN HReg hregLOONGARCH64_R21 ( void ) { return mkHReg(False, HRcInt64, 21, 37); }
+ST_IN HReg hregLOONGARCH64_R22 ( void ) { return mkHReg(False, HRcInt64, 22, 38); }
+ST_IN HReg hregLOONGARCH64_R31 ( void ) { return mkHReg(False, HRcInt64, 31, 39); }
+
+/* Special registers */
+ST_IN HReg hregLOONGARCH64_FCSR3 ( void ) { return mkHReg(False, HRcInt32, 3, 40); }
+
+#undef ST_IN
+
+extern UInt ppHRegLOONGARCH64 ( HReg reg );
+
+/* Number of registers used arg passing in function calls */
+#define LOONGARCH64_N_ARGREGS 8 /* a0 ... a7 */
+
+
+/* --------- Instructions. --------- */
+
+/* Tags for instructions */
+typedef enum {
+   /* Pseudo-insn, used for generating a 64-bit
+      literal to register */
+   LAin_LI          /* load imm */
+} LOONGARCH64InstrTag;
+
+typedef struct {
+   LOONGARCH64InstrTag tag;
+   union {
+      struct {
+         ULong                imm;
+         HReg                 dst;
+      } LI;
+   } LAin;
+} LOONGARCH64Instr;
+
+extern void ppLOONGARCH64Instr ( const LOONGARCH64Instr* i, Bool mode64 );
+
+/* Some functions that insulate the register allocator from details
+   of the underlying instruction set. */
+extern void getRegUsage_LOONGARCH64Instr ( HRegUsage* u,
+                                           const LOONGARCH64Instr* i,
+                                           Bool mode64 );
+extern void mapRegs_LOONGARCH64Instr ( HRegRemap* m, LOONGARCH64Instr* i,
+                                       Bool mode64 );
+extern Int emit_LOONGARCH64Instr (/*MB_MOD*/Bool* is_profInc,
+                                  UChar* buf,
+                                  Int nbuf,
+                                  const LOONGARCH64Instr* i,
+                                  Bool mode64,
+                                  VexEndness endness_host,
+                                  const void* disp_cp_chain_me_to_slowEP,
+                                  const void* disp_cp_chain_me_to_fastEP,
+                                  const void* disp_cp_xindir,
+                                  const void* disp_cp_xassisted );
+
+extern void genSpill_LOONGARCH64 ( /*OUT*/ HInstr** i1, /*OUT*/ HInstr** i2,
+                                   HReg rreg, Int offsetB, Bool mode64);
+extern void genReload_LOONGARCH64 ( /*OUT*/ HInstr** i1, /*OUT*/ HInstr** i2,
+                                    HReg rreg, Int offsetB, Bool mode64);
+extern LOONGARCH64Instr* genMove_LOONGARCH64 ( HReg from, HReg to,
+                                               Bool mode64 );
+
+extern const RRegUniverse* getRRegUniverse_LOONGARCH64 ( void );
+
+extern HInstrArray* iselSB_LOONGARCH64 ( const IRSB*,
+                                         VexArch,
+                                         const VexArchInfo*,
+                                         const VexAbiInfo*,
+                                         Int offs_Host_EvC_Counter,
+                                         Int offs_Host_EvC_FailAddr,
+                                         Bool chainingAllowed,
+                                         Bool addProfInc,
+                                         Addr max_ga );
+
+/* How big is an event check?  See case for Min_EvCheck in
+   emit_LOONGARCH64Instr just above.  That crosschecks what this returns,
+   so we can tell if we're inconsistent. */
+extern Int evCheckSzB_LOONGARCH64 ( void );
+
+/* NB: what goes on here has to be very closely coordinated with the
+   emitInstr case for XDirect, above. */
+extern VexInvalRange chainXDirect_LOONGARCH64 ( VexEndness endness_host,
+                                                void* place_to_chain,
+                                                const void* disp_cp_chain_me_EXPECTED,
+                                                const void* place_to_jump_to );
+
+/* NB: what goes on here has to be very closely coordinated with the
+   emitInstr case for XDirect, above. */
+extern VexInvalRange unchainXDirect_LOONGARCH64 ( VexEndness endness_host,
+                                                  void* place_to_unchain,
+                                                  const void* place_to_jump_to_EXPECTED,
+                                                  const void* disp_cp_chain_me );
+
+/* Patch the counter address into a profile inc point, as previously
+   created by the Min_ProfInc case for emit_LOONGARCH64Instr. */
+extern VexInvalRange patchProfInc_LOONGARCH64 ( VexEndness endness_host,
+                                                void*  place_to_patch,
+                                                const ULong* location_of_counter );
+
+#endif /* ndef __VEX_HOST_LOONGARCH64_DEFS_H */
+
+
+/*---------------------------------------------------------------*/
+/*--- end                             host-loongarch64_defs.h ---*/
+/*---------------------------------------------------------------*/
diff --git a/VEX/priv/host_loongarch64_isel.c b/VEX/priv/host_loongarch64_isel.c
new file mode 100644
index 000000000..eaad2cf70
--- /dev/null
+++ b/VEX/priv/host_loongarch64_isel.c
@@ -0,0 +1,59 @@
+
+/*---------------------------------------------------------------*/
+/*--- begin                           host_loongarch64_isel.c ---*/
+/*---------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details->
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+*/
+
+#include "libvex_basictypes.h"
+#include "libvex_ir.h"
+#include "libvex.h"
+
+#include "main_util.h"
+#include "main_globals.h"
+#include "host_generic_regs.h"
+#include "host_loongarch64_defs.h"
+
+
+/*---------------------------------------------------------*/
+/*--- Insn selector top-level                           ---*/
+/*---------------------------------------------------------*/
+
+/* Translate an entire BB to LOONGARCH64 code. */
+HInstrArray* iselSB_LOONGARCH64 ( const IRSB* bb,
+                                  VexArch arch_host,
+                                  const VexArchInfo* archinfo_host,
+                                  const VexAbiInfo* vbi,
+                                  Int offs_Host_EvC_Counter,
+                                  Int offs_Host_EvC_FailAddr,
+                                  Bool chainingAllowed,
+                                  Bool addProfInc,
+                                  Addr max_ga )
+{
+   return NULL;
+}
+
+
+/*---------------------------------------------------------------*/
+/*--- end                             host_loongarch64_isel.c ---*/
+/*---------------------------------------------------------------*/
diff --git a/VEX/priv/main_main.c b/VEX/priv/main_main.c
index 482047c7a..98d4a81c6 100644
--- a/VEX/priv/main_main.c
+++ b/VEX/priv/main_main.c
@@ -43,6 +43,7 @@
 #include "libvex_guest_s390x.h"
 #include "libvex_guest_mips32.h"
 #include "libvex_guest_mips64.h"
+#include "libvex_guest_loongarch64.h"
 
 #include "main_globals.h"
 #include "main_util.h"
@@ -57,6 +58,7 @@
 #include "host_s390_defs.h"
 #include "host_mips_defs.h"
 #include "host_nanomips_defs.h"
+#include "host_loongarch64_defs.h"
 
 #include "guest_generic_bb_to_IR.h"
 #include "guest_x86_defs.h"
@@ -67,6 +69,7 @@
 #include "guest_s390_defs.h"
 #include "guest_mips_defs.h"
 #include "guest_nanomips_defs.h"
+#include "guest_loongarch64_defs.h"
 
 #include "host_generic_simd128.h"
 
@@ -163,6 +166,14 @@
 #define NANOMIPSST(f) vassert(0)
 #endif
 
+#if defined(VGA_loongarch64) || defined(VEXMULTIARCH)
+#define LOONGARCH64FN(f) f
+#define LOONGARCH64ST(f) f
+#else
+#define LOONGARCH64FN(f) NULL
+#define LOONGARCH64ST(f) vassert(0)
+#endif
+
 /* This file contains the top level interface to the library. */
 
 /* --------- fwds ... --------- */
@@ -541,6 +552,23 @@ IRSB* LibVEX_FrontEnd ( /*MOD*/ VexTranslateArgs* vta,
          vassert(sizeof( ((VexGuestMIPS32State*)0)->guest_NRADDR ) == 4);
          break;
 
+      case VexArchLOONGARCH64:
+         preciseMemExnsFn
+            = LOONGARCH64FN(guest_loongarch64_state_requires_precise_mem_exns);
+         disInstrFn              = LOONGARCH64FN(disInstr_LOONGARCH64);
+         specHelper              = LOONGARCH64FN(guest_loongarch64_spechelper);
+         guest_layout            = LOONGARCH64FN(&loongarch64Guest_layout);
+         offB_CMSTART            = offsetof(VexGuestLOONGARCH64State, guest_CMSTART);
+         offB_CMLEN              = offsetof(VexGuestLOONGARCH64State, guest_CMLEN);
+         offB_GUEST_IP           = offsetof(VexGuestLOONGARCH64State, guest_PC);
+         szB_GUEST_IP            = sizeof( ((VexGuestLOONGARCH64State*)0)->guest_PC );
+         vassert(vta->archinfo_guest.endness == VexEndnessLE);
+         vassert(sizeof(VexGuestLOONGARCH64State) % LibVEX_GUEST_STATE_ALIGN == 0);
+         vassert(sizeof( ((VexGuestLOONGARCH64State*)0)->guest_CMSTART) == 8);
+         vassert(sizeof( ((VexGuestLOONGARCH64State*)0)->guest_CMLEN  ) == 8);
+         vassert(sizeof( ((VexGuestLOONGARCH64State*)0)->guest_NRADDR ) == 8);
+         break;
+
       default:
          vpanic("LibVEX_Translate: unsupported guest insn set");
    }
@@ -878,6 +906,14 @@ static void libvex_BackEnd ( const VexTranslateArgs *vta,
          offB_HOST_EvC_FAILADDR = offsetof(VexGuestMIPS32State,host_EvC_FAILADDR);
          break;
 
+      case VexArchLOONGARCH64:
+         preciseMemExnsFn
+            = LOONGARCH64FN(guest_loongarch64_state_requires_precise_mem_exns);
+         guest_sizeB            = sizeof(VexGuestLOONGARCH64State);
+         offB_HOST_EvC_COUNTER  = offsetof(VexGuestLOONGARCH64State, host_EvC_COUNTER);
+         offB_HOST_EvC_FAILADDR = offsetof(VexGuestLOONGARCH64State, host_EvC_FAILADDR);
+         break;
+
       default:
          vpanic("LibVEX_Codegen: unsupported guest insn set");
    }
@@ -1052,6 +1088,23 @@ static void libvex_BackEnd ( const VexTranslateArgs *vta,
                  || vta->archinfo_host.endness == VexEndnessBE);
          break;
 
+      case VexArchLOONGARCH64:
+         mode64       = True;
+         rRegUniv     = LOONGARCH64FN(getRRegUniverse_LOONGARCH64());
+         getRegUsage
+            = CAST_TO_TYPEOF(getRegUsage) LOONGARCH64FN(getRegUsage_LOONGARCH64Instr);
+         mapRegs      = CAST_TO_TYPEOF(mapRegs) LOONGARCH64FN(mapRegs_LOONGARCH64Instr);
+         genSpill     = CAST_TO_TYPEOF(genSpill) LOONGARCH64FN(genSpill_LOONGARCH64);
+         genReload    = CAST_TO_TYPEOF(genReload) LOONGARCH64FN(genReload_LOONGARCH64);
+         genMove      = CAST_TO_TYPEOF(genMove) LOONGARCH64FN(genMove_LOONGARCH64);
+         ppInstr      = CAST_TO_TYPEOF(ppInstr) LOONGARCH64FN(ppLOONGARCH64Instr);
+         ppReg        = CAST_TO_TYPEOF(ppReg) LOONGARCH64FN(ppHRegLOONGARCH64);
+         iselSB       = LOONGARCH64FN(iselSB_LOONGARCH64);
+         emit         = CAST_TO_TYPEOF(emit) LOONGARCH64FN(emit_LOONGARCH64Instr);
+         vassert(vta->archinfo_host.endness == VexEndnessLE
+                 || vta->archinfo_host.endness == VexEndnessBE);
+         break;
+
       default:
          vpanic("LibVEX_Translate: unsupported host insn set");
    }
@@ -1297,6 +1350,11 @@ VexInvalRange LibVEX_Chain ( VexArch     arch_host,
                                                  place_to_chain,
                                                  disp_cp_chain_me_EXPECTED,
                                                  place_to_jump_to));
+      case VexArchLOONGARCH64:
+         LOONGARCH64ST(return chainXDirect_LOONGARCH64(endness_host,
+                                                       place_to_chain,
+                                                       disp_cp_chain_me_EXPECTED,
+                                                       place_to_jump_to));
       default:
          vassert(0);
    }
@@ -1359,6 +1417,11 @@ VexInvalRange LibVEX_UnChain ( VexArch     arch_host,
                                                  place_to_unchain,
                                                  place_to_jump_to_EXPECTED,
                                                  disp_cp_chain_me));
+      case VexArchLOONGARCH64:
+         LOONGARCH64ST(return unchainXDirect_LOONGARCH64(endness_host,
+                                                         place_to_unchain,
+                                                         place_to_jump_to_EXPECTED,
+                                                         disp_cp_chain_me));
       default:
          vassert(0);
    }
@@ -1389,6 +1452,8 @@ Int LibVEX_evCheckSzB ( VexArch    arch_host )
             MIPS64ST(cached = evCheckSzB_MIPS()); break;
         case VexArchNANOMIPS:
             NANOMIPSST(cached = evCheckSzB_NANOMIPS()); break;
+         case VexArchLOONGARCH64:
+            LOONGARCH64ST(cached = evCheckSzB_LOONGARCH64()); break;
          default:
             vassert(0);
       }
@@ -1432,6 +1497,10 @@ VexInvalRange LibVEX_PatchProfInc ( VexArch    arch_host,
       case VexArchNANOMIPS:
          NANOMIPSST(return patchProfInc_NANOMIPS(endness_host, place_to_patch,
                                                  location_of_counter));
+      case VexArchLOONGARCH64:
+         LOONGARCH64ST(return patchProfInc_LOONGARCH64(endness_host,
+                                                       place_to_patch,
+                                                       location_of_counter));
       default:
          vassert(0);
    }
@@ -1515,6 +1584,7 @@ const HChar* LibVEX_ppVexArch ( VexArch arch )
       case VexArchMIPS32:   return "MIPS32";
       case VexArchMIPS64:   return "MIPS64";
       case VexArchNANOMIPS: return "NANOMIPS";
+      case VexArchLOONGARCH64: return "LOONGARCH64";
       default:              return "VexArch???";
    }
 }
@@ -1585,6 +1655,7 @@ static IRType arch_word_size (VexArch arch) {
       case VexArchMIPS64:
       case VexArchPPC64:
       case VexArchS390X:
+      case VexArchLOONGARCH64:
          return Ity_I64;
 
       default:
@@ -1925,6 +1996,38 @@ static const HChar* show_hwcaps_mips64 ( UInt hwcaps )
    return "Unsupported baseline";
 }
 
+static const HChar* show_hwcaps_loongarch64 ( UInt hwcaps )
+{
+   static const HChar prefix[] = "loongarch64";
+   static const struct {
+      UInt  hwcaps_bit;
+      HChar name[16];
+   } hwcaps_list[] = {
+      { VEX_HWCAPS_LOONGARCH_CPUCFG,  "cpucfg"   },
+      { VEX_HWCAPS_LOONGARCH_LAM,     "lam"      },
+      { VEX_HWCAPS_LOONGARCH_UAL,     "ual"      },
+      { VEX_HWCAPS_LOONGARCH_FP,      "fpu"      },
+      { VEX_HWCAPS_LOONGARCH_LSX,     "lsx"      },
+      { VEX_HWCAPS_LOONGARCH_LASX,    "lasx"     },
+      { VEX_HWCAPS_LOONGARCH_COMPLEX, "complex"  },
+      { VEX_HWCAPS_LOONGARCH_CRYPTO,  "crypto"   },
+      { VEX_HWCAPS_LOONGARCH_LVZP,    "lvz"      },
+      { VEX_HWCAPS_LOONGARCH_X86BT,   "lbt_x86"  },
+      { VEX_HWCAPS_LOONGARCH_ARMBT,   "lbt_arm"  },
+      { VEX_HWCAPS_LOONGARCH_MIPSBT,  "lbt_mips" }
+   };
+   static HChar buf[sizeof(prefix) +
+                    NUM_HWCAPS * (sizeof hwcaps_list[0].name + 1) + 1]; // '\0'
+
+   HChar *p = buf + vex_sprintf(buf, "%s", prefix);
+   UInt i;
+   for (i = 0 ; i < NUM_HWCAPS; ++i) {
+      if (hwcaps & hwcaps_list[i].hwcaps_bit)
+         p = p + vex_sprintf(p, "-%s", hwcaps_list[i].name);
+   }
+   return buf;
+}
+
 #undef NUM_HWCAPS
 
 /* Thie function must not return NULL. */
@@ -1941,6 +2044,7 @@ static const HChar* show_hwcaps ( VexArch arch, UInt hwcaps )
       case VexArchS390X:  return show_hwcaps_s390x(hwcaps);
       case VexArchMIPS32: return show_hwcaps_mips32(hwcaps);
       case VexArchMIPS64: return show_hwcaps_mips64(hwcaps);
+      case VexArchLOONGARCH64: return show_hwcaps_loongarch64(hwcaps);
       default: return NULL;
    }
 }
@@ -2203,6 +2307,11 @@ static void check_hwcaps ( VexArch arch, UInt hwcaps )
             return;
          invalid_hwcaps(arch, hwcaps, "Unsupported baseline\n");
 
+      case VexArchLOONGARCH64:
+         if (!(hwcaps & VEX_HWCAPS_LOONGARCH_ISA_64BIT))
+            invalid_hwcaps(arch, hwcaps, "Unsupported baseline\n");
+         return;
+
       default:
          vpanic("unknown architecture");
    }
diff --git a/VEX/pub/libvex.h b/VEX/pub/libvex.h
index ec50d52ca..c118400a0 100644
--- a/VEX/pub/libvex.h
+++ b/VEX/pub/libvex.h
@@ -60,6 +60,7 @@ typedef
       VexArchMIPS32,
       VexArchMIPS64,
       VexArchNANOMIPS,
+      VexArchLOONGARCH64,
    }
    VexArch;
 
@@ -299,6 +300,22 @@ typedef
                               (VEX_MIPS_PROC_ID(x) == VEX_PRID_IMP_P5600) && \
                               (VEX_MIPS_HOST_FP_MODE(x)))
 
+/* LoongArch baseline capability */
+#define VEX_HWCAPS_LOONGARCH_CPUCFG    (1 << 0)   /* CPU has CPUCFG */
+#define VEX_HWCAPS_LOONGARCH_LAM       (1 << 1)   /* CPU has Atomic instructions */
+#define VEX_HWCAPS_LOONGARCH_UAL       (1 << 2)   /* CPU has Unaligned Access support */
+#define VEX_HWCAPS_LOONGARCH_FP        (1 << 3)   /* CPU has FPU */
+#define VEX_HWCAPS_LOONGARCH_LSX       (1 << 4)   /* CPU has 128-bit SIMD instructions */
+#define VEX_HWCAPS_LOONGARCH_LASX      (1 << 5)   /* CPU has 256-bit SIMD instructions */
+#define VEX_HWCAPS_LOONGARCH_COMPLEX   (1 << 6)   /* CPU has Complex instructions */
+#define VEX_HWCAPS_LOONGARCH_CRYPTO    (1 << 7)   /* CPU has Crypto instructions */
+#define VEX_HWCAPS_LOONGARCH_LVZP      (1 << 8)   /* CPU has Virtualization extension */
+#define VEX_HWCAPS_LOONGARCH_X86BT     (1 << 9)   /* CPU has X86 Binary Translation */
+#define VEX_HWCAPS_LOONGARCH_ARMBT     (1 << 10)  /* CPU has ARM Binary Translation */
+#define VEX_HWCAPS_LOONGARCH_MIPSBT    (1 << 11)  /* CPU has MIPS Binary Translation */
+#define VEX_HWCAPS_LOONGARCH_ISA_32BIT (1 << 30)  /* 32-bit ISA */
+#define VEX_HWCAPS_LOONGARCH_ISA_64BIT (1 << 31)  /* 64-bit ISA */
+
 /* These return statically allocated strings. */
 
 extern const HChar* LibVEX_ppVexArch    ( VexArch );
@@ -1025,6 +1042,10 @@ extern void LibVEX_InitIRI ( const IRICB * );
    ~~~~~
    r21 is GSP.
 
+   loongarch64
+   ~~~~~
+   r31 is GSP.
+
    ALL GUEST ARCHITECTURES
    ~~~~~~~~~~~~~~~~~~~~~~~
    The guest state must contain two pseudo-registers, guest_CMSTART
diff --git a/VEX/pub/libvex_basictypes.h b/VEX/pub/libvex_basictypes.h
index e3f1485d5..b4c81bf54 100644
--- a/VEX/pub/libvex_basictypes.h
+++ b/VEX/pub/libvex_basictypes.h
@@ -198,6 +198,10 @@ typedef  unsigned long HWord;
 #   define VEX_HOST_WORDSIZE 4
 #   define VEX_REGPARM(_n) /* */
 
+#elif defined(__loongarch__) && (__loongarch_grlen == 64)
+#   define VEX_HOST_WORDSIZE 8
+#   define VEX_REGPARM(_n) /* */
+
 #else
 #   error "Vex: Fatal: Can't establish the host architecture"
 #endif
diff --git a/VEX/pub/libvex_guest_loongarch64.h b/VEX/pub/libvex_guest_loongarch64.h
new file mode 100644
index 000000000..ff5982842
--- /dev/null
+++ b/VEX/pub/libvex_guest_loongarch64.h
@@ -0,0 +1,171 @@
+
+/*---------------------------------------------------------------*/
+/*--- begin                        libvex_guest_loongarch64.h ---*/
+/*---------------------------------------------------------------*/
+
+/*
+   This file is part of Valgrind, a dynamic binary instrumentation
+   framework.
+
+   Copyright (C) 2021-2022 Loongson Technology Corporation Limited
+
+   This program is free software; you can redistribute it and/or
+   modify it under the terms of the GNU General Public License as
+   published by the Free Software Foundation; either version 2 of the
+   License, or (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful, but
+   WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+   General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, see <http://www.gnu.org/licenses/>.
+
+   The GNU General Public License is contained in the file COPYING.
+
+   Neither the names of the U.S. Department of Energy nor the
+   University of California nor the names of its contributors may be
+   used to endorse or promote products derived from this software
+   without prior written permission.
+*/
+
+#ifndef __LIBVEX_PUB_GUEST_LOONGARCH64_H
+#define __LIBVEX_PUB_GUEST_LOONGARCH64_H
+
+#include "libvex_basictypes.h"
+
+
+/*---------------------------------------------------------------*/
+/*--- Vex's representation of the LOONGARCH64 CPU state.      ---*/
+/*---------------------------------------------------------------*/
+
+typedef
+   struct {
+      /* Event check fail addr and counter. */
+      /*    0 */ ULong host_EvC_FAILADDR;
+      /*    8 */ UInt  host_EvC_COUNTER;
+      /*   12 */ UInt  _padding0;
+
+      /* CPU Registers */
+      /*   16 */ ULong guest_R0;   /* Constant zero */
+      /*   24 */ ULong guest_R1;   /* Return address */
+      /*   32 */ ULong guest_R2;   /* Thread pointer */
+      /*   40 */ ULong guest_R3;   /* Stack pointer */
+      /*   48 */ ULong guest_R4;   /* Argument registers / Return value */
+      /*   56 */ ULong guest_R5;
+      /*   64 */ ULong guest_R6;   /* Argument registers */
+      /*   72 */ ULong guest_R7;
+      /*   80 */ ULong guest_R8;
+      /*   88 */ ULong guest_R9;
+      /*   96 */ ULong guest_R10;
+      /*  104 */ ULong guest_R11;
+      /*  112 */ ULong guest_R12;  /* Temporary registers */
+      /*  120 */ ULong guest_R13;
+      /*  128 */ ULong guest_R14;
+      /*  136 */ ULong guest_R15;
+      /*  144 */ ULong guest_R16;
+      /*  152 */ ULong guest_R17;
+      /*  160 */ ULong guest_R18;
+      /*  168 */ ULong guest_R19;
+      /*  176 */ ULong guest_R20;
+      /*  184 */ ULong guest_R21;  /* Reserved */
+      /*  192 */ ULong guest_R22;  /* Frame pointer / Static register */
+      /*  200 */ ULong guest_R23;  /* Static registers */
+      /*  208 */ ULong guest_R24;
+      /*  216 */ ULong guest_R25;
+      /*  224 */ ULong guest_R26;
+      /*  232 */ ULong guest_R27;
+      /*  240 */ ULong guest_R28;
+      /*  248 */ ULong guest_R29;
+      /*  256 */ ULong guest_R30;
+      /*  264 */ ULong guest_R31;
+
+      /*  272 */ ULong guest_PC;   /* Program counter */
+
+      /* FPU Registers */
+      /*  280 */ ULong guest_F0;   /* Argument registers / Return value */
+      /*  288 */ ULong guest_F1;
+      /*  296 */ ULong guest_F2;   /* Argument registers */
+      /*  304 */ ULong guest_F3;
+      /*  312 */ ULong guest_F4;
+      /*  320 */ ULong guest_F5;
+      /*  328 */ ULong guest_F6;
+      /*  336 */ ULong guest_F7;
+      /*  344 */ ULong guest_F8;   /* Temporary registers */
+      /*  352 */ ULong guest_F9;
+      /*  360 */ ULong guest_F10;
+      /*  368 */ ULong guest_F11;
+      /*  376 */ ULong guest_F12;
+      /*  384 */ ULong guest_F13;
+      /*  392 */ ULong guest_F14;
+      /*  400 */ ULong guest_F15;
+      /*  408 */ ULong guest_F16;
+      /*  416 */ ULong guest_F17;
+      /*  424 */ ULong guest_F18;
+      /*  432 */ ULong guest_F19;
+      /*  440 */ ULong guest_F20;
+      /*  448 */ ULong guest_F21;
+      /*  456 */ ULong guest_F22;
+      /*  464 */ ULong guest_F23;
+      /*  472 */ ULong guest_F24;  /* Static registers */
+      /*  480 */ ULong guest_F25;
+      /*  488 */ ULong guest_F26;
+      /*  496 */ ULong guest_F27;
+      /*  504 */ ULong guest_F28;
+      /*  512 */ ULong guest_F29;
+      /*  520 */ ULong guest_F30;
+      /*  528 */ ULong guest_F31;
+
+      /*  536 */ UChar guest_FCC0;  /* Condition Flag Registers */
+      /*  537 */ UChar guest_FCC1;
+      /*  538 */ UChar guest_FCC2;
+      /*  539 */ UChar guest_FCC3;
+      /*  540 */ UChar guest_FCC4;
+      /*  541 */ UChar guest_FCC5;
+      /*  542 */ UChar guest_FCC6;
+      /*  543 */ UChar guest_FCC7;
+      /*  544 */ UInt  guest_FCSR;  /* FP Control and Status Register */
+
+      /* Various pseudo-regs mandated by Vex or Valgrind. */
+      /* Emulation notes */
+      /*  548 */ UInt  guest_EMNOTE;
+
+      /* For clflush: record start and length of area to invalidate */
+      /*  552 */ ULong guest_CMSTART;
+      /*  560 */ ULong guest_CMLEN;
+
+      /* Used to record the unredirected guest address at the start of
+         a translation whose start has been redirected.  By reading
+         this pseudo-register shortly afterwards, the translation can
+         find out what the corresponding no-redirection address was.
+         Note, this is only set for wrap-style redirects, not for
+         replace-style ones. */
+      /*  568 */ ULong guest_NRADDR;
+
+      /* Fallback LL/SC support. */
+      /*  576 */ ULong guest_LLSC_SIZE; /* 0==no transaction, else 4 or 8. */
+      /*  584 */ ULong guest_LLSC_ADDR; /* Address of the transaction. */
+      /*  592 */ ULong guest_LLSC_DATA; /* Original value at ADDR. */
+
+      /* VexGuestLOONGARCH64State should have a 16-aligned size */
+      /*  600 */ ULong _padding1;
+} VexGuestLOONGARCH64State;
+
+/*---------------------------------------------------------------*/
+/*--- Utility functions for LOONGARCH64 guest stuff.          ---*/
+/*---------------------------------------------------------------*/
+
+/* ALL THE FOLLOWING ARE VISIBLE TO LIBRARY CLIENT. */
+
+/* Initialise all guest LOONGARCH64 state. */
+
+extern
+void LibVEX_GuestLOONGARCH64_initialise ( /*OUT*/
+                                          VexGuestLOONGARCH64State* vex_state );
+
+#endif /* ndef __LIBVEX_PUB_GUEST_LOONGARCH64_H */
+
+/*---------------------------------------------------------------*/
+/*---                              libvex_guest_loongarch64.h ---*/
+/*---------------------------------------------------------------*/
-- 
2.39.1

